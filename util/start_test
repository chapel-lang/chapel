#!/bin/csh -f
#
#
# Main test script for Chapel compiler -- based on testing system from
# the ZPL testing system, originally developed by Jason Secosky with
# later mods by Brad Chamberlain, Sung-Eun Choi, Steve Deitz, and
# E Christopher Lewis.
#
# DIRECTORY STRUCTURE
#
#   Bin/     -- contains binary files/scripts required by the testing
#               system, such as the timedexec script which kills a
#               test if it takes too long
#   Logs/    -- logs of testing runs go here by default
#   Samples/ -- sample tests go here; these are for illustration only
#               and won't be run by default.  To try running the
#               test system against these samples, use:
#                      start_test ./Samples
#   Share/   -- a place to put codes to share with other developers.
#               These will not be run by default.
#   */       -- all other directories will contain tests
#
#
# EXECUTIVE SUMMARY
#
# The overall flow of the testing system is that by default it will
# recursively descend into subdirectories looking for Chapel programs
# to compile and run (*.chpl).  The output of these runs will
# typically be logged in a file stored in the Logs/ subdirectory of
# the testing directory, along with a summary of the errors reported
# (determined by grepping for the string "[Error", so don't have your
# program print this out) and the status of "future tests" -- those
# that are not expected to work, but are checked in for the purpose of
# sharing and staking out future work.
#
# The main arguments to start_test are a list of directories and/or
# list of files that should be tested.  The test system will test all
# of the files listed and then all of the directories, including their
# children (unless the -norecurse flag is used).  If no list of
# directories or files is provided, the starting directory is either:
#
#   * "test" if start_test is invoked from $CHPL_HOME
#
#   * "."  otherwise (i.e., all subdirectories of the current
#                     directory will be tested).
#
# In addition to source-based tests (*.chpl), tests can also execute
# arbitrary commands (see sub_test below).
#
#
# COMMAND-LINE OPTIONS
#
# The '-h' option lists the options that the script accepts and the
# default values.  Current options are:
#
#   option     argument               default value
#   ---------  ---------------------  -------------
#              [list of directories]  "test" if in $CHPL_HOME, "." otherwise
#              [list of tests]        ""
#   -compiler  <compiler executable>  $CHPL_HOME/bin/<platform>/chpl
#   -compopts  <option list>          "--cc-warnings"
#   -execopts  <option list>          ""
#   -launchcmd <launcher command>     ""
#   -norecurse
#   -componly
#   -performance
#   -futures
#   -futuresonly
#   -valgrind
#   -valgrindexe
#   -notee
#   -comm [none|gasnet]               $CHPL_HOME/util/comm.pl
#   -suppress <suppression file>
#   -interpret (DEPRECATED)
#   -logfile   <log filename>         $testdir/Logs/<username>.<platform>.log
#                                     (where $testdir is $CHPL_HOME/test if
#                                     it exists, $CHPL_HOME/examples otherwise)
#
# All options can be used with a double-dash format as well 
# (e.g. --compopts).
#
# The -compiler option allows the user to specify the compiler to test
# if it is something other than the obvious one in the current SVN
# structure.  This lets one run other people's compilers, old copies
# of compilers, etc.
#
# The -compopts option allows the user to specify a set of compiler
# options that should be used on every invocation to the compiler.
# Additional compiler options can be specified on a directory-by-
# directory basis using mechanisms described below (COMPOPTS/.compopts).
# By default, -compopts is set to --cc-warnings, and additional
# -compopts arguments will append to this list.  If, for some reason,
# one wants to disable the --cc-warnings flag, currently the only
# way to do so is by specifying "-compopts --no-cc-warnings" to
# reverse the effects of that flag.
#
# The -componly option specifies that this testing run should only
# be compiled and not executed; this causes success of a test to
# be related to the success or failure of the compile step, not to
# its execution.
#
# The -execopts option allows the user to specify a set of execution
# options that should be used on every invocation of a program.  As
# with compiler options, these can be ammended in each subdirectory.
#
# The -launchcmd option allows the user to specify a program launch
# utility to use to start generated executables. When tests are
# executed, the launchcmd is prepended to the command line used. This
# allows, for example, for a binary generated by a cross compiler to
# be copied over to the target machine before it is executed.
#
# The -norecurse flag requests that the base directory/ies be tested
# but that no subdirectories be visited recursively.  This is useful
# for pinpointing the testing of a single directory when you do not
# want to test any of its subdirectories.
#
# The -logfile option indicates where the log of the test run should
# be kept.  By default it's based on the user's name and the platform
# you're testing.  At the end of the run, a second log file named
# <logfile>.summary will be generated containing only the Errors and
# future tests that were logged.
#
# A -suppress option can be used to specify a file listing tests that
# should be ignored for a particular run if they fail (and an error
# will be generated if they pass when they were expected to fail).
# The format of this suppress file is to list a single test per line
# with optional comment lines starting with an initial '#' character.
# After the whole testing system has been run, the tests in the
# suppression file will be grepped out of the summary log file.
#
# The -valgrind option specifies that the compiler and generated
# executable should be run using valgrind in order to find errors.
# The -valgrindexe option specifies that the generated executable
# should be run using valgrind, but not the compiler.
#
# The -notee option indicates that "tee" should not be used.  This was
# added due to a sense that tee was breaking the nightly regression
# runs on the Cygwin platform.
#
# The -futures option specifies that the testing system should test
# both future and non-future tests.  By default, future tests are
# skipped over.  The -futuresonly option specifies that the testing
# system should test only the future tests and not the others.
#
# The -performance flag specifies that the testing system should
# search for and execute performance tests within the testing
# system.  A test foo.chpl is considered a performance test if a
# file "foo.perfkeys" exists.  This file contains a string per
# line that is used to read performance-related cues from the
# test's compiler+execution output file.  For example, if a test
# generates a line "Time: x.yz seconds", putting the key "Time:"
# into its .perfkeys file would cause the testing system to grab
# the value "x.yz" out of the output file (all non-whitespace 
# characters after the key string until the next whitespace 
# character).  These data values will then be written to a file
# named $CHPL_TEST_PERF_DIR/<machine name>/foo.dat (where
# $CHPL_TEST_PERF_DIR is "." by default) in a  TAB-separated manner 
# for graphing or display using gnuplot or Excel.
#
# When running with the -performance flag, compiler and executable
# options are specified in files with .perfcompopts and 
# .perfexecopts since they will most likely require different
# compiler options (to specify optimization, turn off bounds
# checking) and execution options (to request timings and other
# unpredictable values to be printed out, whereas they're likely
# to be squelched in the correctness run).
#
# Success/failure summaries after a performance run indicate
# whether all the performance keys for a test were matched or not.
# In particular, a failure indicates that a test's performance
# keys couldn't all be found.
#
# The -interpret option requests that the compiler be executed in
# interpreter mode.  This will cause the test system to invoke the
# compiler to interpret the program rather than compile and run it.
# Future tests, those utilizing executable options (execopts), and
# those that are not executed (noexec) tests are skipped when this
# flag is invoked.  In addition, a directory can be requested to
# be skipped by dropping a NOINTERP file into it.  Because the
# Chapel compiler's interpreter feature is currently disabled, this
# flags is currenty deprecated.
#
# The -comm option requests that testing be performed with respect to
# a specific comm layer.  At the time of this writing, none and gasnet
# are the two supported options.  Choosing something other than "none"
# will cause "-nl 1" to be prefixed to the generated executable's
# command-line options to set the number of locales.  Setting the
# number of locales to something other than 1 can be done using
# NUMLOCALES and <testname>.numlocales files in the testing
# directories themselves.  Using these mechanisms to set the number of
# locales to 0 will cause the testing system to not use the -nl flag
# by default.  Any directory or test that has a NUMLOCALES file, or
# that has a .numlocales file specifying a number other than 0 or 1
# will be skipped when using "none" as the communic layer (either
# explicitly or by not specifying a -comm flag).
#
#
# STRUCTURE OF TEST DIRECTORIES
#
# By default, setting up a subdirectory for testing simply consists
# of creating the directory, putting Chapel (.chpl) source files
# into it and an expected output file (.good) for each source file
# (using the same base name).  Upon reaching such a directory, the
# testing system will run the specified compiler on each Chapel
# source file using the specified compiler options, then (assuming
# the compile completed successfully, execute the resulting program 
# using the specified execution options.  The output from both the
# compilation and the execution are concatenated and diff'd against
# the .good file.  This allows programs that are supposed to generate
# errors, warnings, and correct programs to all be tested using the
# same mechanisms.  
#
# If the output for a test varies by machine, communication layer, or
# platform name, files named <testname>.<machname>.good,
# <testname>.comm-<commlayer>.good, or <testname>.<platform>.good can
# be used to specify the output for such tests, where "machname" is
# the output of "uname -n" with any "." qualifiers after the machine
# name stripped off, commlayer is the communication layer being tested
# (e.g., "none" or "gasnet") and "platform" is the value of
# $CHPL_TARGET_PLATFORM.  The most specific good file will be used, in
# the order: machname, commlayer, platform, generic.
#
# Tests that are not yet expected to work can be marked as such
# by creating a <testname>.future file.  The presence of the
# .future file will prevent the test from counting toward our
# nightly successes and regressions, and is intended to allow
# tests to be checked in to share them between multiple developers
# in-line with other tests that work.  In general, once a test
# is working and stable, its future file should be removed and 
# should not be re-added (for future failures of the test should
# be counted as regressions).  The .future file should contain
# the userid of the developer whose court it's in on the first
# line (this will appear in the test system's summaries), or some
# other categorization of what the future is dependent on to pass.
# Subsequent lines can contain notes and will be ignored by the
# testing system.
#
# As mentioned above, running the test system in interpreter mode
# does not attempt to execute tests with .future files.  The
# interpreter mode of the testing system has a parallel mechanism
# for creating future tests using a .ifuture file (the "i"
# stands for interpreter)
#
# If the test-writer wants to redirect standard input from a file,
# they may do so by supplying a .stdin file with the same base
# name as the test itself (e.g., if mytest.stdin exists, it will
# be piped into stdin when running the executable created from
# mytest.chpl).  If no such file exists, standard input is piped
# from /dev/null (i.e., tests can't read from the console...)
#
# Particular subdirectories can also be customized if necessary.
# Note that such customizations are not inherited recursively by
# further subdirectories, but apply only to the directory in
# question (we might consider changing this in future versions).
# The customizations are as follows:
#
#   - if the subdirectory contains an executable sub_test script,
#     that script will be used to run the tests in that directory
#     rather than the default sub_test script (located in the Bin
#     directory).  A sub_test script may take whatever actions it
#     wants, and is simply expected to generate any errors using
#     the "[Error ...]" format so that it will show up in the
#     summary.  Similarly, the script should generate any warnings
#     or successful tests using "[Warning ...]" "[Success ...]"
#     messages for consistency.  The sub_test script will be
#     sent two arguments: (1) the compiler to use, and (2) the
#     location of this main test/ directory.  The compiler and
#     execution options will be stored in environment variables
#     named COMPOPTS and EXECOPTS, respectively.
#
#  - if the subdirectory contains a NOTEST file, that directory
#    will not be considered for testing.  This can be useful for
#    disabling subdirectories containing tests that don't work
#    yet, or subdirectories that contain input files for other
#    tests (though they will also be ignored if they fail to
#    contain any .chpl files...).  This may also be selected for
#    a single test, foo.chpl, by creating a foo.notest file.
#
#  - if the subdirectory contains a SKIPIF file, the contents of
#    the file will be checked to determine whether or not the
#    directory's tests should be skipped.  The current format of
#    the SKIPIF file is as follows:
#      # ...          : a line starting with a # is a comment
#      <blank>        : a blank line is skipped
#      <var> == <val> : checks to see if envvar "var" is "val"
#      <var> != <val> : checks to see if envvar "var" is not "val"
#    All of the lines of the "==" and "!=" form are logically
#    or'd together, and if any of them are true, the test is
#    skipped.  As with other options, a SKIPIF condition can
#    be placed on a file-by-file basis using a <testname>.skipif
#    file.  Tests that are explicitly named on the start_test
#    command line will be tested regardless of any .skipif files.
#
#    Planned extensions to this capability:
#    - ability to test for things like "compopts contains <val>"
#    - ability to logically-and filters together
#
#  - if the subdirectory contains a NOEXEC file, any executables
#    built in that directory will not attempt to be executed.
#    Rather, only the compiler output will be diffed against the
#    expected output (note that when a compile fails, this will
#    also happen automatically).  This may also be selected for
#    a single test, foo.chpl, by creating a foo.noexec file.
#
#  - if the subdirectory contains a NOVGRBIN file and the -valgrind
#    flag was used, the generated binary will not be run using 
#    valgrind (the compiler still would be).
#
#  - if the subdirectory contains a COMPOPTS or EXECOPTS file,
#    the options listed in that file will be added to the compiler
#    and execution options for that subdirectory.  In addition, 
#    a test named foo.chpl can add its own compilation and execution
#    options by specifying them in foo.compopts and foo.execopts.
#
#  - also added support for a LASTCOMPOPTS file that contains
#    compiler options to be added after the source file.  Thus:
#    ./chpl <-compopts> <COMPOPTS> source.chpl <LASTCOMPOPTS>
# 
#  - if the subdirectory contains a COMPSTDIN file, the contents of
#    COMPSTDIN will be piped into the execution of the compile step as
#    stdin.  I can add a similar feature for the execution step as
#    soon as there's need for it.
#
#  - if the subdirectory contains a CATFILES file, then the files
#    listed in that file will be concatenated to the end of the
#    compiler/execution output for each test.  For tests that
#    generate files (either as a result of the compilation or
#    as part of the executable's behavior), this can be used to
#    ensure that the generated file's contents are correct without
#    writing a specialized sub_test script.  Again, this file should
#    be a single line with no linefeeds.  In addition, a test named 
#    foo.chpl can add its own concatenation files by specifying them 
#    in foo.catfiles.
#
#  - if the subdirectory contains an executable PREDIFF file, that
#    file will be executed prior to running any diff command and
#    will be sent three arguments: 1) the name of the current test,
#    2) the name of the output file that the diff is going to
#    be taken against, and 3) the compiler being used.  A 
#    test-specific PREDIFF script can be added  by using a foo.prediff
#    script.
#
#  - similarly, actions desired before running the generated
#    executable can be specified using a PREEXEC or foo.preexec
#    script.  (other such commands can be added to various
#    stages of the sub_test script on request).
#
#  - if the subdirectory contains a TIMEOUT file, then that file
#    will be read to determine the number of seconds that the tests
#    in the directory should be allowed to run before being killed.
#    The default is currently 5 minutes.  A test foo.chpl can also
#    override the timeout just for itself by supplying a timeout
#    value in a foo.timeout file.
#
#  - using subdirectory-specific svn:ignore properties can also be
#    very helpful so that files generated during testing won't
#    clutter the results of a svn status command.
#
# Again, to see a sample run of the testing system, look through
# the Samples/ directory, then run:
#
#     ./start_test Samples
#
# and inspect the Samples/ and Logs/ subdirectories to see what
# was generated.
#

set user = `whoami`

#
# unset things that users may have set in their environment
#
unsetenv CHPL_DEVELOPER

# Commented this out, because it only seems useful in shared environments:
## Make sure that other testers can modify what another 
## tester does
#umask 002

#
if ($?CHPL_HOME) then
    if (! -d $CHPL_HOME || ! -x $CHPL_HOME) then
        echo "Error: CHPL_HOME must be a legal directory"
        exit 1
    endif
else
    echo "Error: CHPL_HOME must be set in order to run start_test"
    exit 1
endif

#
# Set standard CHPL_* environment variables for use by skipif files,
# if they are not
#
if ($?CHPL_HOST_PLATFORM == 0) then
    setenv CHPL_HOST_PLATFORM `$CHPL_HOME/util/platform.pl --host`
endif

if ($?CHPL_TARGET_PLATFORM == 0) then
    setenv CHPL_TARGET_PLATFORM `$CHPL_HOME/util/platform.pl --target`
endif

if ($?CHPL_HOST_COMPILER == 0) then
    setenv CHPL_HOST_COMPILER `$CHPL_HOME/util/compiler.pl --host`
endif

if ($?CHPL_TARGET_COMPILER == 0) then
    setenv CHPL_TARGET_COMPILER `$CHPL_HOME/util/compiler.pl --target`
endif

if ($?CHPL_THREADS == 0) then
    setenv CHPL_THREADS `$CHPL_HOME/util/threads.pl`
endif

if ($?CHPL_COMM == 0) then
    setenv CHPL_COMM `$CHPL_HOME/util/comm.pl`
endif

set testdir = "$CHPL_HOME/test"
if (! -d $testdir || ! -x $testdir) then
    set testdir = "$CHPL_HOME/examples"
endif
if (! -d $testdir || ! -x $testdir) then
    echo "Error: Cannot find $CHPL_HOME/test or $CHPL_HOME/examples"
    exit 1
endif
set logtmp = $testdir/Logs/$user.tmp.log
set datestr = `date +"%y%m%d.%H%M%S"`

if (! -e $testdir/Logs) then
   mkdir $testdir/Logs
endif



set platform = `$CHPL_HOME/util/platform.pl`

#
# some sets to get locale, environment reasonable
#
if ($platform != "sunos") then
    setenv LC_ALL C
    setenv LANG en_US
endif
limit stacksize 8192k


set execopts = ""
set compiler = ""
set compopts = "--cc-warnings"
set launchcmd = ""
set dirlist = ""
set testlist = ""
set logfile = "$testdir/Logs/$user.$platform.log"
set valgrind = 0
set valgrindexe = 0
set interpret = 0
set performance = 0
set testfutures = 0
set testfuturesonly = 0
set testnotests = 0
set recurse = 1
set tee = "tee"
set numlocales = 0
set comm = `$CHPL_HOME/util/comm.pl`
set suppressions = ""

while ( $#argv > 0 )
	switch ( $argv[1] )
	case -execopts:
	case --execopts:
		shift
		set execopts = "$execopts $argv[1]"
		shift
		breaksw
	case -compiler:
	case --compiler:
		shift
		set compiler = $argv[1]
		shift
		breaksw
        case -launchcmd:
        case --launchcmd:
                shift
                set launchcmd = "$argv[1]"
                shift
                breaksw
	case -compopts:
	case --compopts:
		shift
		set compopts = "$compopts $argv[1]"
		shift
		breaksw
	case -logfile:
	case --logfile:
		shift
		set logfile = $argv[1]
		shift
		breaksw
	case -valgrind:
	case --valgrind:
		shift
		set valgrind = 1
		breaksw
        case -futures:
        case --futures:
                shift
                set testfutures = 1
                breaksw
        case -futuresonly
        case --futuresonly
                shift
                set testfuturesonly = 1
                breaksw
        case -i:
        case --interpret:
        case -interpret:
                shift
                set interpret = 1
                breaksw
        case --performance:
        case -performance:
                shift
                set performance = 1
                breaksw
        case -norecurse:
        case --norecurse:
                shift
                set recurse = 0
                breaksw
	case -componly:
	case --componly:
		shift
		setenv CHPL_COMPONLY true
		breaksw
        case -valgrindexe:
        case --valgrindexe:
                shift
                set valgrindexe = 1
                breaksw
        case -notee:
        case --notee:
                shift
                set tee = "$testdir/Bin/cat2File"
                breaksw
        case -comm:
        case --comm:
                shift
                set comm = $argv[1]
                if ($comm == "") then
                    set comm = "none"
                endif
                shift
                breaksw
        case -suppress:
        case --suppress:
                shift
                set suppressions = $argv[1]
                shift
                breaksw
	case -h:
	case -help:
        case --help
		echo Usage and defaults\:
		echo "     start_test <file list> <directory list>"
		echo "          -compiler <path>     (currently: $CHPL_HOME/bin/$platform/chpl)"
		echo "          -compopts <options>  (currently: '--cc-warnings')"
		echo "          -execopts <options>  (currently: '')"
                echo "          -launchcmd <command> (currently: '')"
                echo "          -norecurse"
		echo "          -componly"
                echo "          -performance"
                echo "          -futures"
                echo "          -futuresonly"
		echo "          -valgrind"
                echo "          -valgrindexe"
                echo "          -notee"
                echo "          -comm [comm|gasnet]  (currently: $comm)"
                echo "          -suppress <filename>"
#                echo "          -interpret (or -i)"
		echo "          -logfile <file>      (currently: $testdir/Logs/$user.$platform.log)"
		echo "          -h, -help"
		exit 0
		breaksw
	default:
                if ( -d "$argv[1]" && -x "$argv[1]") then
#                    echo "$argv[1] is a directory"
                    set dirlist = "$dirlist $argv[1]"
                    shift
                    breaksw
                else if ( -r "$argv[1]") then
#                    echo "$argv[1] is a file"
                    set testlist = "$testlist $argv[1]"
                    shift
                    breaksw
                else
                    echo \[ERROR: Unknown command line parameter \"$argv[1]\", aborting.\]
                    shift
		exit 1
		breaksw
	endsw
end

if ($comm != "none") then
    set numlocales = "1"
endif

set invocationDir = "$cwd"
setenv CHPL_TEST_INVOKE_DIR "$invocationDir"

echo \[Starting Chapel regression tests - $datestr\] |& $tee $logtmp
echo \[starting directory: \"$invocationDir\"] |& $tee -a $logtmp
echo \[test directory: \"$testdir\"\] |& $tee -a $logtmp

echo \[platform: $platform\] |& $tee -a $logtmp
# see if valgrind is on.  If it is, reset the compiler
if ($valgrind) then
    echo \[valgrind: ON\] |& $tee -a $logtmp
    setenv CHPL_TEST_VGRND_COMP on
    setenv CHPL_TEST_VGRND_EXE on
    which valgrind > /dev/null
    if ( $status != 0 ) then
	echo ERROR: can\'t find valgrind |& $tee -a $logtmp
	exit 1
    endif
else
    setenv CHPL_TEST_VGRND_COMP off
    if ($valgrindexe) then
        echo \[valgrind: EXE only\] |& $tee -a $logtmp
        setenv CHPL_TEST_VGRND_EXE on
    else
        echo \[valgrind: OFF\] |& $tee -a $logtmp
        setenv CHPL_TEST_VGRND_EXE off
    endif
endif

if ($compiler == "") then
  set compiler = "$CHPL_HOME/bin/$platform/chpl"
endif

if ($interpret) then
    echo \[interpreter: ON\] |& $tee -a $logtmp
    set compopts = "-i $compopts"
    setenv CHPL_TEST_INTERP on
else
    echo \[interpreter: OFF\] |& $tee -a $logtmp
    setenv CHPL_TEST_INTERP off
endif

if ($performance) then
    echo \[performance tests: ON\] |& $tee -a $logtmp
    setenv CHPL_TEST_PERF on
else
    echo \[performance tests: OFF\] |& $tee -a $logtmp
endif


# if compiler exists then get absolute path name for
if ( -f $compiler && -x $compiler ) then
	pushd `dirname $compiler` >& /dev/null
	set compiler = $cwd/`basename $compiler`
	popd >& /dev/null

	echo \[compiler: \"$compiler\"\] |& $tee -a $logtmp
else
	echo \[Cannot find or execute compiler: \"$compiler\"\] \
		|& $tee -a $logtmp
        exit 1
endif

echo \[compopts: \"$compopts\"\] |& $tee -a $logtmp

echo \[execopts: \"$execopts\"\] |& $tee -a $logtmp

echo \[launchcmd: \"$launchcmd\"\] |& $tee -a $logtmp

echo \[comm: \"$comm\"\] |& tee -a $logtmp
setenv CHPL_COMM $comm

if ($numlocales == "0") then
    echo \[numlocales: \"\(default\)\"\] |& tee -a $logtmp
else
    echo \[numlocales: \"$numlocales\"\] |& tee -a $logtmp
endif

if ("$dirlist" == "" && "$testlist" == "") then
    pushd $CHPL_HOME >& /dev/null
    set chplhome = $cwd
    popd >& /dev/null
    if ("$cwd" == "$chplhome") then
        set dirlist = "test"
    else
        set dirlist = "."
    endif
endif

# get absolute path for each directory
set absdirs = ""
foreach dir ($dirlist)
    pushd "$dir" >& /dev/null
    set currentdir = "$cwd"
    popd >& /dev/null

    set absdirs = "$absdirs $currentdir"
end


echo \[tests: \"$testlist\"] |& $tee -a $logtmp

if ($recurse == 1) then
    echo \[directories: \"$absdirs\"] |& $tee -a $logtmp
else
    echo \[directories: \(nonrecursive\): \"$absdirs\"] |& tee -a $logtmp
endif

#if logfile directory exists, then get absolute path for
if ( -d `dirname $logfile` && -x `dirname $logfile` ) then
	pushd `dirname $logfile` >& /dev/null
	set logfile = `pwd`/`basename $logfile`
	popd >& /dev/null

	echo \[logfile: \"$logfile\"\] |& $tee -a $logtmp
else
	echo \[Permission denied for logfile directory: \"`dirname $logfile`\"\] \
		|& $tee -a $logtmp
	exit 1
endif

if ( -w $logfile ) then
	echo ""
	echo \[Removing log file with duplicate name \"$logfile\"\]
	rm -f $logfile
endif

# Move temp log file ($logtmp) we have been accumulating to actual log file
#   now that we know the name of the actual log file
mv $logtmp $logfile



#
# test all of the tests that the user listed (if any).
#

# For this mode, test futures, non-futures, and notests
setenv CHPL_TEST_FUTURES 1
setenv CHPL_TEST_NOTESTS 1
setenv CHPL_TEST_SINGLES 1
foreach test ($testlist)
    set basedir = `dirname $test`
    set testname = `basename $test`

    pushd $basedir >& /dev/null
    echo " " |& $tee -a $logfile
    echo "[Working on file $test]" |& $tee -a $logfile

    if (-x ./sub_test) then
        set sub_test = ./sub_test
    else
	set sub_test = $testdir/Bin/sub_test
    endif

    if (-x ./Bin/sub_clean) then
        set sub_clean = ./Bin/sub_clean
    else
        set sub_clean = $testdir/Bin/sub_clean
    endif
    setenv COMPOPTS "$compopts"
    setenv EXECOPTS "$execopts"
    setenv NUMLOCALES "$numlocales"
    setenv LAUNCHCMD "$launchcmd"
    setenv CHPL_ONETEST "$testname"
    echo "[Starting $sub_test `date`]" |& $tee -a $logfile

    $sub_clean |& $tee -a $logfile
    $sub_test "$compiler" |& $tee -a $logfile

    unsetenv CHPL_ONETEST

    popd >& /dev/null
end


#
# test all of the directories that the user specified
#

setenv CHPL_TEST_SINGLES 0

# for this mode, only test futures and notests as specified
# by the command-line flags
if ($testfuturesonly == 1) then
    setenv CHPL_TEST_FUTURES 2
else
    if ($testfutures == 1) then
        setenv CHPL_TEST_FUTURES 1
    else
        setenv CHPL_TEST_FUTURES 0
    endif
endif

if ($testnotests == 1) then
    setenv CHPL_TEST_NOTESTS 1
else
    setenv CHPL_TEST_NOTESTS 0
endif


foreach absdir ($absdirs)
    # if specified to start in a specific directory, start there
    set basedir = $absdir
    cd $basedir

    echo "[Working from directory $absdir]"

    # execute script that is located in each directory
    #   Recursively list all directories (have a : in the line)
    #   Don't include directories known not to be for tests
    #   Take off : with sed
    #
    if ($recurse == 1) then
        set dirs = `ls -R |& grep ":" | grep -v "\.:" | grep -v "Permission denied" | grep -v Bin | grep -v Logs | grep -v Samples | grep -v Share | grep -v perfdat | sed 's/://g'`
    # gotta add ./ on in case explicit start directories were specified
        set dirs = (./ $dirs)
    else
        set dirs = (./)
    endif

    foreach dir ($dirs)
        cd $basedir
	if ( -x $dir ) then
            pushd $dir >& /dev/null
            set dir = $cwd
	    popd >& /dev/null

	    cd $dir
	else
	    echo \["Warning: Cannot cd into" $dir "skipping directory."\]|&\
			$tee -a $logfile
	    continue
	endif

       	echo " " |& $tee -a $logfile
        echo "[Working on directory $dir]" |& $tee -a $logfile

	set numtests = `(ls *.{chpl,v} |& grep -v "No match" | wc -l)`

        if (-e ./SKIPIF) then
            set skiptest = `$testdir/Bin/testEnv.pl ./SKIPIF`
            if ($skiptest == 1) then
                echo "[Skipping directory based on SKIPIF environment settings]"
                continue
            endif
        endif

	if ((! -e ./NOTEST && ($numtests != 0 || -x ./sub_test) && \
            (($CHPL_TEST_INTERP == "off") || (! -e ./NOINTERP && ! -e ./NOEXEC && ! -e ./EXECOPTS)))) then
            if (-x ./sub_test) then
                set sub_test = ./sub_test
	    else
		set sub_test = $testdir/Bin/sub_test
	    endif
            if (-x ./Bin/sub_clean) then
                set sub_clean = ./Bin/sub_clean
            else
                set sub_clean = $testdir/Bin/sub_clean
            endif
	    setenv COMPOPTS "$compopts"
            setenv EXECOPTS "$execopts"
            setenv NUMLOCALES "$numlocales"
            setenv LAUNCHCMD "$launchcmd"
	    echo "[Starting $sub_test `date`]" |& $tee -a $logfile

	    $sub_clean |& $tee -a $logfile
	    $sub_test "$compiler" |& $tee -a $logfile
	else
	    echo \["No tests in directory " $dir\] |& $tee -a $logfile
	endif
    end
end

# return to where we started
cd $invocationDir

echo \[Done with tests - `date +"%y%m%d.%H%M%S"`\] |& $tee -a $logfile
echo " " |& $tee -a $logfile

# Output grep to a temp file, don't want to infinite loop
set futuremarker = "^Future"
set errormarker = "^\[Error"
if ($?CHPL_COMPONLY) then
    set successmarker = "^\[Success compiling"
else
    set successmarker = "^\[Success matching"
endif

echo \[Test Summary - $datestr\] |& $tee $logfile.summary
grep "$errormarker" $logfile |& $tee -a $logfile.summary
if ($suppressions != "") then
    $testdir/Bin/filterSuppressions.pl $suppressions $logfile.summary
endif
grep "$futuremarker" $logfile |& $tee -a $logfile.summary

set successes = `grep "$successmarker" $logfile | wc -l`

# count failures from the summary file rather than the log file because
# it's already have its suppressions removed => better count
set failures = `grep "$errormarker" $logfile.summary | wc -l`
set futures = `grep "$futuremarker" $logfile | wc -l`

echo \[\Summary: \#Successes = $successes \| \#Failures = $failures \| \#Futures = $futures\] |& $tee -a $logfile.summary

echo \[END\] |& $tee -a $logfile.summary
cat $logfile.summary >> $logfile

echo ''
echo
