#!/bin/csh -f
#
#
# Main test script for Chapel compiler -- based on testing system from
# the ZPL testing system, originally developed by Jason Secosky with
# later mods by Brad Chamberlain, Sung-Eun Choi, Steve Deitz, and
# E Christopher Lewis.
#
# Executive Summary: The overall flow of the testing system is that it
# will recursively descend into subdirectories looking for Chapel
# programs to compile and run (*.chpl) as well as for other tests to
# run (sub_test).  The output of these runs will typically be logged
# in a file stored in the Logs/ subdirectory, as will a summary of the
# errors reported (determined by grepping for the string "[Error", so
# don't have your program print this out) and the status of "future"
# tests -- those that have never worked, but are checked in for the
# purpose of sharing and placeholding.
#
# Here's the directory structure:
#
#   Bin/     -- contains binary files/scripts required by the testing
#               system, such as the timedexec script which kills a
#               test if it takes too long
#   Logs/    -- logs of testing runs go here by default
#   Samples/ -- sample tests go here; these are for illustration only
#               and won't be run by default.  To try running the
#               test system against these samples, use:
#                      start_test -startdir ./Samples
#   Share/   -- a place to put codes to share with other developers.
#               These will not be run by default.
#   */       -- all other directories will contain tests
#
# The start_test script kicks off all the action.  With no arguments,
# it will run all the tests using the defaults.  The '-h' option lists
# the options that the script accepts and the default values.  Current
# options are:
#
#   option     argument               default value
#   ---------  ---------------------  -------------
#   -compiler  <compiler executable>  ../compiler/chpl
#   -compopts  <option list>          ""
#   -execopts  <option list>          ""
#   -startdir  <test subdir>          .
#   -logfile   <log filename>         ./Logs/<username>.log
#   -valgrind
#
# These options can be used with a double-dash as well 
# (e.g. --compopts).
#
# The -compiler option allows the user to specify the compiler to test
# if it is something other than the obvious one in the current CVS
# structure.  This lets one run other people's compilers, old copies
# of compilers, etc.
#
# The -compopts option allows the user to specify a set of compiler
# options that should be used on every invocation to the compiler.
# Additional compiler options can be specified on a directory-by-
# directory basis.
#
# The -execopts option allows the user to specify a set of execution
# options that should be used on every invocation of a program.  As
# with compiler options, these can be ammended in each subdirectory.
#
# The -startdir option allows the user to specify a subdirectory of
# the testing system to start in (and limit itself to).  Assuming
# that tests are sorted into subdirectories by useful features, this
# allows you to run a subset of the tests easily.
#
# The -logfile option indicates where the log of the test run should
# be kept.  By default it's based on the user's name.  If the log
# file already exists, you will be prompted at the beginning of the
# run whether you want to delete that file or not.  At the end of
# the run, a second log file named <logfile>.summary will be
# generated containing only the Errors that were logged.
#
# The -valgrind option specifies that the compiler and generated
# executable should be run using valgrind in order to find errors.
# The -valgrindexe option specifies that the generated executable
# should be run using valgrind, but not the compiler.
#
# By default, setting up a subdirectory for testing simply consists
# of creating the directory, putting Chapel (.chpl) source files
# into it and an expected output file (.good) for each source file
# (using the same base name).  Upon reaching such a directory, the
# testing system will run the specified compiler on each Chapel
# source file using the specified compiler options, then (assuming
# the compile completed successfully, execute the resulting program 
# using the specified execution options.  The output from both the
# compilation and the execution are concatenated and diff'd against
# the .good file.  This allows programs that are supposed to generate
# errors, warnings, and correct programs to all be tested using the
# same mechanisms.
#
# Tests that are not yet expected to work can be marked as such
# by creating a <testname>.future file.  The presence of the
# .future file will prevent the test from counting toward our
# nightly successes and regressions, and is intended to allow
# tests to be checked in to share them between multiple developers
# in-line with other tests that work.  In general, once a test
# is working and stable, its future file should be removed and 
# should not be re-added (for future failures of the test should
# be counted as regressions).  The .future file should contain
# the userid of the developer who's court it's in on the first
# line (this will appear in the test system's summaries).
# Subsequent lines can contain notes and will be ignored by the
# testing system.
#
# If the test-writer wants to redirect standard input from a file,
# they may do so by supplying a .stdin file with the same base
# name as the test itself (e.g., if mytest.stdin exists, it will
# be piped into stdin when running the executable created from
# mytest.chpl).  If no such file exists, standard input is piped
# from /dev/null (i.e., tests can't read from the console...)
#
# Particular subdirectories can also be customized if necessary.
# Note that such customizations are not inherited recursively by
# further subdirectories, but apply only to the directory in
# question (we might consider changing this in future versions).
# The customizations are as follows:
#
#   - if the subdirectory contains an executable sub_test script,
#     that script will be used to run the tests in that directory
#     rather than the default sub_test script (located in this
#     directory).  A sub_test script may take whatever actions it
#     wants, and is simply expected to generate any errors using
#     the "[Error ...]" format so that it will show up in the
#     summary.  Similarly, the script should generate any warnings
#     or successful tests using "[Warning ...]" "[Success ...]"
#     messages for consistency.  The sub_test script will be
#     sent two arguments: (1) the compiler to use, and (2) the
#     location of this main test/ directory.  The compiler and
#     execution options will be stored in environment variables
#     named COMPOPTS and EXECOPTS, respectively.
#
#  - if the subdirectory contains a NOTEST file, that directory
#    will not be considered for testing.  This can be useful for
#    disabling subdirectories containing tests that don't work
#    yet, or subdirectories that contain input files for other
#    tests (though they will also be ignored if they fail to
#    contain any .chpl files...)
#
#  - if the subdirectory contains a NOEXEC file, any executables
#    built in that directory will not attempt to be executed.
#    Rather, only the compiler output will be diffed against the
#    expected output (note that when a compile fails, this will
#    also happen automatically).
#
#  - if the subdirectory contains a NOVGRBIN file and the -valgrind
#    flag was used, the generated binary will not be run using 
#    valgrind (the compiler still would be).
#
#  - if the subdirectory contains a COMPOPTS or EXECOPTS file,
#    the options listed in that file will be added to the compiler
#    and execution options for that subdirectory.  In addition, 
#    a test named foo.chpl can add its own compilation and execution
#    options by specifying them in foo.compopts and foo.execopts.
#
#  - also added support for a LASTCOMPOPTS file that contains
#    compiler options to be added after the source file.  Thus:
#    ./chpl <-compopts> <COMPOPTS> source.chpl <LASTCOMPOPTS>
# 
#  - if the subdirectory contains a COMPSTDIN file, the file named by
#    COMPSTDIN will be piped into the execution of the compile step as
#    stdin.  I can add a similar feature for the execution step as
#    soon as there's need for it.
#
#  - if the subdirectory contains a CATFILES file, then the files
#    listed in that file will be concatenated to the end of the
#    compiler/execution output for each test.  For tests that
#    generate files (either as a result of the compilation or
#    as part of the executable's behavior), this can be used to
#    ensure that the generated file's contents are correct without
#    writing a specialized sub_test script.  Again, this file should
#    be a single line with no linefeeds.  In addition, a test named 
#    foo.chpl can add its own concatenation files by specifying them 
#    in foo.catfiles.
#
#  - if the subdirectory contains an executable PREDIFF file, that
#    file will be executed prior to running any diff command and
#    will be sent three arguments: 1) the name of the current test,
#    2) the name of the output file that the diff is going to
#    be taken against, and 3) the compiler being used.  A 
#    test-specific PREDIFF script can be added  by using a foo.prediff
#    script.
#
#  - similarly, actions desired before running the generated
#    executable can be specified using a PREEXEC or foo.preexec
#    script.  (other such commands can be added to various
#    stages of the sub_test script on request).
#
#  - if the subdirectory contains a TIMEOUT file, then that file
#    will be read to determine the number of seconds that the tests
#    in the directory should be allowed to run before being killed.
#    The default is currently 5 minutes.  A test foo.chpl can also
#    override the timeout just for itself by supplying a timeout
#    value in a foo.timeout file.
#
#  - subdirectory-specific .cvsignore files can also be very 
#    helpful so that files generated during testing won't clutter
#    the results of a cvs -nq update command.
#
# Also worth describing here is the start_clean script which walks
# the directory structure in a similar manner and cleans up --
# removing the generated executables, core files, and *.tmp files
# which store any mismatching output.  The user can also specify
# subdirectory-specific things to clean up using a CLEANFILES
# file that lists other targets to remove (called with the -rf
# flag, so subdirectories will work here as well).  The idea is
# that after start_clean runs, the testing system should be left
# in a state pretty close to what's checked into the CVS tree.
#
# Again, to see a sample run of the testing system, look through
# the Samples/ directory, then run:
#
#     ./start_test -startdir Samples
#
# and inspect the Samples/ and Logs/ subdirectories to see what
# was generated.  Then use:
#
#     ./start_clean -startdir Samples
#
# to clean back up again.
#

set user = `whoami`

#
# unset things that users may have set in their environment
#
unsetenv CHPL_SYSTEM_DIR
unsetenv CHPL_DEVELOPER

#
# try to squelch GC warnings about large allocations -- we may want
# to debug this eventually; they seem to flit in and out 
# nondeterministically from one run to the next.  For now, we'll just
# turn them off.
#
setenv GC_NO_BLACKLIST_WARNING 1

#
# some sets to get locale, environment reasonable
#
setenv LC_ALL C
setenv LANG en_US
limit stacksize 8192k


# Commented this out, because it only seems useful in shared environments:
## Make sure that other testers can modify what another 
## tester does
#umask 002

#
set logtmp = ./Logs/$user.tmp.log
set datestr = `date +"%y%m%d.%H%M%S"`
echo \[Starting Chapel regression tests - $datestr\] |& tee $logtmp

# remember what directory to return to (the current working directory)
set testdir = $cwd
echo \[pwd: \"$testdir\"\] |& tee -a $logtmp

set execopts = ""
set compiler = ""
set compopts = ""
set startdir = "$testdir"
set logfile = "$testdir/Logs/$user.log"
set valgrind = 0
set valgrindexe = 0

set platform = `../util/platform`;

while ( $#argv > 0 )
	switch ( $argv[1] )
	case -execopts:
	case --execopts:
		shift
		set execopts = "$argv[1]"
		# echo \[execopts: \"$execopts\"\] |& tee -a $logtmp
		shift
		breaksw
	case -compiler:
	case --compiler:
		shift
		set compiler = $argv[1]
		# echo \[compiler: \"$compiler\"\] |& tee -a $logtmp
		shift
		breaksw
	case -compopts:
	case --compopts:
		shift
		set compopts = "$argv[1]"
		# echo \[compopts: \"$compopts\"\] |& tee -a $logtmp
		shift
		breaksw
	case -startdir:
	case --startdir:
		shift
		set startdir = $argv[1]
		# echo \[starting-dir: \"$startdir\"\] |& tee -a $logtmp
		shift
		breaksw
	case -logfile:
	case --logfile:
		shift
		set logfile = $argv[1]
		# echo \[log-file: \"$logfile\"\] |& tee -a $logtmp
		shift
		breaksw
	case -valgrind:
	case --valgrind:
		shift
		set valgrind = 1
		breaksw
        case -valgrindexe:
        case --valgrindexe:
                shift
                set valgrindexe = 1
                breaksw
	case -h:
	case -help:
        case --help
		echo Usage and defaults\:
		echo "     start_test"
		echo "          -compiler ../compiler/$platform/chpl[.nogc]"
		echo "          -compopts" \"\"
		echo "          -execopts" \"\"
		echo "          -startdir ."
		echo "          -logfile ./Logs/$user.log"
		echo "          -valgrind"
                echo "          -valgrindexe"
		echo "          -h, -help"
		exit 0
		breaksw
	default:
		echo \[ERROR: Unknown command line parameter \"$argv[1]\", aborting.\] |& tee -a $logtmp
		exit 1
		breaksw
	endsw
end


echo \[platform: $platform\]
# see if valgrind is on.  If it is, reset the compiler
if ($valgrind) then
    echo \[valgrind: ON\]
    setenv CHPL_TEST_VGRND_COMP on
    setenv CHPL_TEST_VGRND_EXE on
    which valgrind > /dev/null
    if ( $status != 0 ) then
	echo ERROR: can\'t find valgrind |& tee -a $logtmp
	exit 1
    endif
    if ($compiler == "") then
        set compiler = "../compiler/$platform/chpl-nogc"
    endif
else
    setenv CHPL_TEST_VGRND_COMP off
    if ($valgrindexe) then
        echo \[valgrind: EXE only\]
        setenv CHPL_TEST_VGRND_EXE on
    else
        echo \[valgrind: OFF\]
        setenv CHPL_TEST_VGRND_EXE off
    endif
    if ($compiler == "") then
        set compiler = "../compiler/$platform/chpl"
    endif
endif


# if compiler exists then get absolute path name for
if ( -f $compiler && -x $compiler ) then
	pushd `dirname $compiler` >& /dev/null
	set compiler = $cwd/`basename $compiler`
	popd >& /dev/null

	echo \[compiler: \"$compiler\"\] |& tee -a $logtmp
else
	echo \[Cannot find or execute compiler: \"$compiler\"\] \
		|& tee -a $logtmp
        exit 1
endif

echo \[compopts: \"$compopts\"\] |& tee -a $logtmp

echo \[execopts: \"$execopts\"\] |& tee -a $logtmp

# if startdir exists then get absolute path name for
if ( -d "$startdir" && -x "$startdir" ) then
	pushd "$startdir" >& /dev/null
	set startdir = "$cwd"
	popd >& /dev/null

	echo \[startdir: \"$startdir\"\] |& tee -a $logtmp
else
	echo \[Permission denied for starting directory: \"$startdir\"\] \
		|& tee -a $logtmp
	exit 1
endif

#if logfile directory exists, then get absolute path for
if ( -d `dirname $logfile` && -x `dirname $logfile` ) then
	pushd `dirname $logfile` >& /dev/null
	set logfile = `pwd`/`basename $logfile`
	popd >& /dev/null

	echo \[logfile: \"$logfile\"\] |& tee -a $logtmp
else
	echo \[Permission denied for logfile directory: \"`dirname $logfile`\"\] \
		|& tee -a $logtmp
	exit 1
endif

if ( -w $logfile ) then
	echo ""
	echo \[Removing log file with duplicate name \"$logfile\"\]
	rm -f $logfile
endif

# Move temp log file ($logtmp) we have been accumulating to actual log file
#   now that we know the name of the actual log file
mv $logtmp $logfile

# if specified to start in a specific directory, start there
set basedir = $testdir
if ( $startdir != $cwd ) then
	set basedir = $startdir
	cd $basedir
endif

# execute script that is located in each directory
#   Recursively list all directories (have a : in the line)
#   Don't include output or RCS directories (-v says don't include)
#   Take off : with sed
#
set dirs = `ls -R |& grep ":" | grep -v "\.:" | grep -v "Permission denied" | grep -v "CVS" | grep -v Bin | grep -v Logs | grep -v Samples | grep -v Share | sed 's/://g'`
# gotta add ./ on in case -startdir is specified
set dirs = (./ $dirs)

#echo "dirs is $dirs"
#echo "cwd is $cwd"

foreach dir ($dirs)
	if ( -x $dir ) then
		pushd $dir >& /dev/null
		set dir = $cwd
		popd >& /dev/null

		cd $dir
	else
		echo \["Warning: Cannot cd into" $dir "skipping directory."\]|&\
			tee -a $logfile
		continue
	endif
       	echo " " |& tee -a $logfile
	set numtests = `(ls *.{chpl,v} |& grep -v "No match" | wc -l)`
	if (! -e ./NOTEST && ($numtests != 0 || -x ./sub_test)) then
		if (-x ./sub_test) then
		    set sub_test = ./sub_test
		else
		    set sub_test = $testdir/sub_test
		endif
                if (-x ./sub_clean) then
                    set sub_clean = ./sub_clean
                else
                    set sub_clean = $testdir/sub_clean
                endif
		setenv COMPOPTS "$compopts"
		setenv EXECOPTS "$execopts"
		echo "[Starting $sub_test `date`]"
		$sub_clean "$testdir" |& tee -a $logfile
		$sub_test "$compiler" "$testdir" |& tee -a $logfile
	else
		echo \["No tests in directory " $dir\] |& \
			tee -a $logfile
	endif
	cd $basedir
end

# return to directory where we started and remove lock
cd $testdir

echo \[Done with tests - `date +"%y%m%d.%H%M%S"`\] |& tee -a $logfile
echo " " |& tee -a $logfile

# Output grep to a temp file, don't want to infinite loop
set futuremarker = "^Future"
set errormarker = "^\[Error"
set successmarker = "^\[Success matching"

echo \[Test Summary - $datestr\] |& tee $logfile.summary
grep "$errormarker" $logfile |& tee -a $logfile.summary
grep "$futuremarker" $logfile |& tee -a $logfile.summary

set successes = `grep "$successmarker" $logfile | wc -l`
set failures = `grep "$errormarker" $logfile | wc -l`
set futures = `grep "$futuremarker" $logfile | wc -l`
echo \[\Summary: \#Successes = $successes \| \#Failures = $failures \| \#Futures = $futures\] |& tee -a $logfile.summary
echo \[END\] |& tee -a $logfile.summary
cat $logfile.summary >> $logfile
echo ''
echo
