==============================================
Chapel Computer Language Benchmarks Game Codes
==============================================

This directory contains Chapel versions of the Computer Language
Benchmarks Game programs (http://benchmarksgame.alioth.debian.org/)
written in Chapel.  In these versions, we strive for a combination of
elegant use of Chapel and performance.  Most of these codes are
written for serial or parallel single-locale (shared-memory)
execution, following the lead of the competition.

At present, this directory contains the following codes:

    binarytrees.chpl    : Allocates and deallocates many, many binary trees
    chameneosredux.chpl : Simulates meetings between color-changing Chameneos
    fannkuchredux.chpl  : Performs many operations on small arrays
    mandelbrot.chpl     : Plots the mandelbrot set [-1.5-i,0.5+i] on a bitmap
    meteor.chpl         : Performs a parallel search for all solutions to a
                          puzzle
    meteor-fast.chpl    : A less readable, but much faster version of meteor.
    nbody.chpl          : Performs an n-body simulation of the Jovian planets
    pidigits.chpl       : Computes digits of pi using GMP, if available
    regexdna.chpl       : Performs DNA matching
    spectralnorm.chpl   : Calculates the spectral norm of an infinite matrix
    threadring.chpl     : Passes a token between a large number of threads

Over time, we plan to create versions of all the benchmarks and to
enter Chapel into the competition.  Draft versions of other benchmarks
that have not yet been promoted to the release can be found in our git
repository under the test/studies/shootout/ directory.

The provided Makefile can be used to compile the programs, or they can
be run in correctness or performance modes using the Chapel testing
system.  (See doc/developer/bestPractices/TestSystem.rst in the Chapel
git repository: http://github.com/chapel-lang/chapel)

Note that chameneosredux.chpl has non-deterministic output.


Future work / TODO
==================
The following are a list of planned improvements to Chapel and/or our
implementations that would benefit the codes:


binarytrees.chpl
----------------
o The Chapel compiler should really be able to infer the return types
  of these recursive functions...

o Related: the type function Tree.build() could be made into a
  constructor except that the compiler can't resolve the return type
  of the constructor because it's recursive (which is silly since it's
  a constructor); yet we can't declare the return type because it's a
  constructor.  I.e., we should be able to write:

    proc Tree(item, depth) {
      this.item = item;
      if depth {
        left = new Tree(2*item-1, depth-1);
        right = new Tree(2*item-1, depth-1);
      }
    }

o It seems like we should be able to write a strength-reduction
  oriented overload of the ** operator in order to replace the '1 <<'
  expression with a 2** operation without loss of performance (looking
  for param base expressions equal to 2 (or a power of 2?).  I believe
  we already specialize ** for certain integral param exponents, but
  not for the base expression?


chameneosredux.chpl
-------------------
o add user-level support for an enum iterator and replace array in
  printColorEquations() with it

o add support for a param enum.size query (not sure we'd actually use
  this, though...)

o once we map to C11 atomics/utilize memory order arguments, can
  performance be improved via different memory orders?

o should the language support local enums?  If so, move 'digit' into
  spellInt().  Currently, it seems to break the cast operator within
  the function (maybe a point-of-instantiation issue?  or where default
  functions are inserted?)

o once Chapel has initializers distinct from assignment, add support
  for initialization of atomic types, which would remove the need for
  the MeetingPlace constructor; and/or add support for direct
  assignment to atomics which would accomplish the same thing even
  before initializers come on-line.

o would we want to have a digiterator in the standard library?  An
  iterator that yields digits for a number?  (in base b)?

o add support for compiler analysis that switch statements on enums
  cover all cases in order to be able to replace 'otherwise' with
  'when yellow' and not get a compiler error.

o Chapel has discussed supporting some standard record-wrapped class
  types in order to avoid the need to use 'new' and 'delete' while
  still supporting "single logical instance" semantics.  It seems that
  both the meeting place and chameneos population would benefit from
  this in terms of avoiding the cleanup steps.


fannkuchredux.chpl
------------------
o optimize slice assignment such that pp[0..i] = p[0..i] can be
  written without penalty

o create better story for serializing array assignments by default
  when arrays are short? or parallelism is already full-throttle?

o as part of DynamicIters and/or chunking library, create version
  of dynamic iterator that will return chunk directly

o improve magic number default for nChunks?

o make scans not generate warnings and use them to compute/initialize
  fact?

o remove warning for serial whole-array assignment when RHS is serial
  and then use an initfact() iterator / procedure to initialize fact[]
  at declaration time

o should globals be allowed to be declared below main()?  If so, move
  fact[] to the bottom of the file?


fasta.chpl
----------
o Shouldn't ascii() return an int(8)/uint(8) by default?

o We should introduce local "static" variables (using some other
  keyword) and use it to define some of the variables that are
  currently at global or outer scopes unnecessarily

o Should writef("%s", str) and write(str) be equivalent?  If so,
  it looks like we have a bug.


k-nucleotide
------------
o In addition, we currently combine per-task associative domains into
  the shared one an element at a time, but using the new bulk-add
  interface for irregular domains, we should be able to do this
  faster (at present time, however, bulk-add is only supported by
  sparse, not associative :(

o I also find myself wondering whether the coforall + chunking could
  be converted into a forall with a '+ reduce' intent on associative
  domains.  Does that make sense?  What would it take for it to work?
  
o Consider the difference in performance between associative and chaining;
  tighten up associative domain to try and close this gap
  - support user-defined hashes to avoid double-hashing
  - BHarsh thinks there's an extraneous % operation?
  - what else...?

o Good motivation for optimizing 1D array reallocations with a common
  low bound?

o Why does '(data:[] uint(8)) op= 0x20' not work?

o Shouldn't ascii() return an int(8)/uint(8) by default?

o Should readline() support an overload that takes an array of int(8)?

o Could we use a 'sorted' iterator to print freqs rather than storing into
  an array?

o Shouldn't we be able to do a param for loop over a lo..#size param range


mandelbrot.chpl
---------------
o extend the dynamic() iterators for ranges to support domains and
  collapse the two nested loops into a single loop over a 2D domain.

o add an 'unroll' capability to loops and use it to unroll the 'for
  off ...' loop which is about twice as fast with manual unrolling.
  (we weren't willing to unroll it manually in this version)

o have the compiler automatically optimize writes to 'stdout' in
  serial code segments to avoid the need to manually get a lock-free
  channel to it.

o explore expressing the complex values using Chapel's 'complex' type,
  even if it means plucking C.re and C.im out and operating on them
  directly rather than using higher-level complex operations to avoid
  overheads associated with using cleaner complex operations.


meteor.chpl
-----------
o once we have a .size query on enums, we should replace uses of PIVOT
  with this

o would using 1-based arrays rather than 0-based clean anything up?

o It would be nice to write:
    var x = min reduce for x in X do x;
  as:
    serial var x = min reduce X;
  or (preferably):
    var x = serial min reduce X;
  this suggests either adding a serial expression or permitting
  reductions to be prefixed by 'serial'



nbody.chpl
----------
o explore possibility of enabling vectorization (perhaps by applying
  'vectorizeOnly() to tuple operations?)
  - explore padding to better align velocity field

o have compiler eliminate inner multiplies

o support sum-of-squares library function for all tuples?  (collections?)
  Improve and lean on Norm module more?  Optimize reductions so that
  they could be used for sum of squares without penalty?

o moving 'ref b1 = bodies[i]' up to outer loop doesn't seem to help,
  why is that?  Also const vs. ref for bodies[i] in energy computation?

o have compiler eliminate and hoist common subexpressions better so
  that b1/b2 refs/consts aren't necessary for good performance.

o as initializers are enabled, change 'mass' from 'var' to 'const'
  field


pidigits.chpl
-------------
o promote mpz_t types to a record-based implementation with:
  - a better name
  - arithmetic operators defined for it
  - automatic memory reclamation when it leaves scope
  - support for native Chapel types rather than exposing C types
    (using safecasts at any downward-facing interfaces)


revcomp.chpl
------------
o Shouldn't ascii() return an int(8)/uint(8) by default?

o The pattern ascii(mystring[i]) seems like it ought to be very
  optimizable compared to what we do now, and to support param
  versions in the event that mystring and 'i' are both params.  As a
  short-term workaround, ascii() could take an optional "index"
  argument that would allow us to write this as ascii(mystring, i).
  Longer-term, I wonder what could be done to reduce the overhead of
  this pattern (and maybe, more generally, string indexing).

o Should we be able to support a param loop over lo..hi by 2?

o Each time I use readline() I'm sad that I have to declare a
  'numRead' variable ahead of it.  Could this return a tuple
  or something to avoid having to pass in this argument?



spectralnorm.chpl
-----------------
o spectral norm really wants partial reductions... :(

o What could we do to not pass 'tmp' in as an input argument?  Should
  Chapel support static variables?

o open question: What would it take to (efficiently) have the helper
  routines return the result they're computing rather than taking it
  in as an input argument?  This is related to ongoing questions
  about returning arrays and records and optimizing such returns...

o do we have an opportunity to take advantage of vectorization?
  (could it be as simple as 'vectorizeOnly-ing' the reduction loops?
  Or unrolling them?)

o are our reductions overly heavyweight in the serial case?  (e.g., do
  we still use synchronized values?)  Is there more we could do to
  improve them?

o are the domain queries costing us more than we'd like?

o should Chapel's dynamic() iterators default to a chunksize of 1?


threadring.chpl
---------------
o map Chapel's sync vars more directly down to Qthreads' sync vars
  to avoid space and time overheads
