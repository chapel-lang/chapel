\sekshun{Data Parallelism}
\label{Data_Parallelism}
\index{data parallelism}
\index{parallelism!data}

Chapel provides two explicit data-parallel constructs (the
forall-statement and the forall-expression) and several idioms that
support data parallelism implicitly (whole-array assignment, function
and operator promotion, reductions, and scans).

This chapter details data parallelism as follows:
\begin{itemize}
\item \rsec{Forall} describes the forall statement.
\item \rsec{Forall_Expressions} describes forall expressions
\item \rsec{Forall_Intents} specifies how variables from outer scopes
are handled within forall statements and expressions.
\item \rsec{Promotion} describes promotion.
\item \rsec{Reductions_and_Scans} describes reductions and scans.
\item \rsec{data_parallel_knobs} describes the configuration constants for
controlling default data parallelism.
\end{itemize}       

Data-parallel constructs may result in accesses to the same variable
from different tasks, possibly due to aliasing using
\chpl{ref} argument intents or forall intents, among others.
Such accesses are subject to the Memory Consistency Model
(\rsec{Memory_Consistency_Model}).

\section{The Forall Statement}
\label{Forall}
\index{forall@\chpl{forall} (see also statements, forall)}
\index{loops!forall (see also statements, forall)}
\index{data parallelism!forall}
\index{statements!forall@\chpl{forall}}

The forall statement is a concurrent variant of the for statement
described in~\rsec{The_For_Loop}.

\subsection{Syntax}
\label{forall_syntax}
\index{statements!forall@\chpl{forall}!syntax}

The syntax of the forall statement is given by
\begin{syntax}
forall-statement:
  `forall' index-var-declaration `in' iteratable-expression task-intent-clause[OPT] `do' statement
  `forall' index-var-declaration `in' iteratable-expression task-intent-clause[OPT] block-statement
  `forall' iteratable-expression task-intent-clause[OPT] `do' statement
  `forall' iteratable-expression task-intent-clause[OPT] block-statement
  [ index-var-declaration `in' iteratable-expression task-intent-clause[OPT] ] statement
  [ iteratable-expression task-intent-clause[OPT] ] statement
\end{syntax}
As with the for statement, the indices may be omitted if they are
unnecessary and the \chpl{do} keyword may be omitted before a block
statement.  The square bracketed form is a syntactic convenience.

The handling of the outer variables within the forall statement and
the role of \sntx{task-intent-clause} are defined in \rsec{Forall_Intents}.

\subsection{Execution and Serializability}
\label{forall_semantics}
\index{statements!forall@\chpl{forall}!semantics}

The forall statement evaluates the loop body once for each element
yielded by the \sntx{iteratable-expression}.  Each instance of the
forall loop's body may be executed concurrently with the others, but
this is not guaranteed.  In particular, the loop must be serializable.
Details regarding concurrency and iterator implementation are
described in~\ref{Parallel_Iterators}.

This differs from the semantics of the \chpl{coforall} loop, discussed
in~\rsec{Coforall}, where each iteration is guaranteed to run using a
distinct task.  The \chpl{coforall} loop thus has potentially higher
overhead than a forall loop with the same number of iterations, but in
cases where concurrency is required for correctness, it is essential.

\index{leading the execution of a loop}
\index{data parallelism!leader iterator}
In practice, the number of tasks that will be used to evaluate
a \chpl{forall} loop is determined by the object or iterator that
is \emph{leading} the execution of the loop, as is the mapping of
iterations to tasks.

This concept will be formalized in future drafts of the Chapel
specification. For now, the primer on parallel iterators
in the online documentation provides a brief introduction:
\\ %formatting
\mbox{$$ $$ $$ $$ $$} %indent
\url{https://chapel-lang.org/docs/primers/parIters.html}
\\
Please also refer to \emph{User-Defined Parallel Zippered Iterators in
Chapel}, published in the PGAS 2011 workshop.

Control continues with the statement following the forall loop only
after every iteration has been completely evaluated.  At this point,
all data accesses within the body of the forall loop will be
guaranteed to be completed.

A \chpl{return} statement may not be lexically enclosed in a forall
statement. A \chpl{yield} statement may only be lexically enclosed in
a forall statement that is within a parallel iterator
\rsec{Parallel_Iterators}.
A \chpl{break} statement may not be used to exit a forall statement.
A \chpl{continue} statement skips the rest of the current iteration
of the forall loop.

\begin{chapelexample}{forallStmt.chpl}
In the code
\begin{chapelpre}
config const N = 5;
var a: [1..N] int;
var b = [i in 1..N] i;
\end{chapelpre}
\begin{chapel}
forall i in 1..N do
  a(i) = b(i);
\end{chapel}
the user has stated that the element-wise assignments can execute
concurrently.  This loop may be executed serially with a single task,
or by using a distinct task for every iteration, or by using a number
of tasks where each task executes a number of iterations.  This loop
can also be written as
\begin{chapel}
[i in 1..N] a(i) = b(i);
\end{chapel}
\begin{chapelpost}
writeln(a);
\end{chapelpost}
\begin{chapeloutput}
1 2 3 4 5
\end{chapeloutput}
\end{chapelexample}

\subsection{Zipper Iteration}
\label{forall_zipper}
\index{statements!forall@\chpl{forall}!zipper iteration}

Zipper iteration has the same semantics as described
in~\rsec{Zipper_Iteration} and~\rsec{Parallel_Iterators} for parallel
iteration.

\pagebreak
\section{The Forall Expression}
\label{Forall_Expressions}
\index{data parallelism!forall expressions}
\index{forall expressions (see also expressions, forall)}
\index{expressions!forall}

The forall expression is a concurrent variant of the for expression
described in~\rsec{For_Expressions}.

\subsection{Syntax}
\label{forall_expr_syntax}
\index{expressions!forall!syntax}

The syntax of a forall expression is given by
\begin{syntax}
forall-expression:
  `forall' index-var-declaration `in' iteratable-expression task-intent-clause[OPT] `do' expression
  `forall' iteratable-expression task-intent-clause[OPT] `do' expression
  [ index-var-declaration `in' iteratable-expression task-intent-clause[OPT] ] expression
  [ iteratable-expression task-intent-clause[OPT] ] expression
\end{syntax}
As with the for expression, the indices may be omitted if they are
unnecessary.  The \chpl{do} keyword is always required in the
keyword-based notation.  The bracketed form is a syntactic
convenience.

The handling of the outer variables within the forall expression and
the role of \sntx{task-intent-clause} are defined in \rsec{Forall_Intents}.

\subsection{Execution}
\label{Forall_Expression_Execution}
\index{expressions!forall!semantics}

A forall expression is an iterator that executes a forall loop (\rsec{Forall}),
evaluates the body expression on each iteration of the loop,
and yields each resulting value.

When a forall expression is used to initialize a variable, such as
\begin{chapel}
var X = forall iterableExpression() do computeValue();
\end{chapel}
the variable will be inferred to have an array type.
The array's domain is defined by the \sntx{iterable-expression}
following the same rules as for promotion, both in the regular
case \rsec{Promotion} and in the zipper case \rsec{Zipper_Promotion}.

\begin{chapelexample}{forallExpr.chpl}
The code
\begin{chapel}
writeln(+ reduce [i in 1..10] i**2);
\end{chapel}
\begin{chapeloutput}
385
\end{chapeloutput}
applies a reduction to a forall-expression that evaluates the square
of the indices in the range \chpl{1..10}.
\end{chapelexample}

The forall expression follows the semantics of the forall statement as
described in~\ref{forall_semantics}.

\subsection{Zipper Iteration}
\index{expressions!forall!zipper iteration}
Forall expression also support zippered iteration semantics as
described in~\rsec{Zipper_Iteration} and~\rsec{Parallel_Iterators} for
parallel iteration.

\subsection{Filtering Predicates in Forall Expressions}
\label{Filtering_Predicates_Forall}
\index{expressions!forall!and conditional expressions}
\index{expressions!forall!filtering}

A filtering predicate is an if expression that is immediately enclosed
by a forall expression and does not have an
else clause.  Such an if expression filters the iterations of the
forall expression.  The iterations for which the condition does not
hold are not reflected in the result of the forall expression.

When a forall expression with a filtering predicate is captured into
a variable, the resulting array has a 1-based one-dimensional domain.

\begin{chapelexample}{forallFilter.chpl}
The following expression returns every other element starting with the
first:
\begin{chapelpre}
var s: [1..10] int = [i in 1..10] i;
var result =
\end{chapelpre}
\begin{chapel}
[i in 1..s.numElements] if i % 2 == 1 then s(i)
\end{chapel}
\begin{chapelpost}
;
writeln(result);
\end{chapelpost}
\begin{chapeloutput}
1 3 5 7 9
\end{chapeloutput}
\end{chapelexample}


\section{Forall Intents}
\label{Forall_Intents}
\index{forall intents}
\index{shadow variables}
\index{data parallelism!forall intents}
\index{data parallelism!shadow variables}
\index{statements!forall@\chpl{forall}!forall intents}
\index{statements!forall@\chpl{forall}!shadow variables}

If a variable is referenced within the lexical scope of a
forall statement or expression and is declared outside
that statement or expression, it is subject to \emph{forall intents},
analogously to task intents (\rsec{Task_Intents})
for task-parallel constructs. That is, the variable is considered
to be passed as an actual argument to
each task function created by the object or iterator leading
the execution of the loop. If no tasks are created,
it is considered to be an actual argument to the leader or standalone
iterator itself. All references to the variable
within the forall statement or expression implicitly refer
to a \emph{shadow variable}, i.e.
the corresponding formal argument of the task function
or the leader/standalone iterator.

Each formal argument of a task function or iterator has the default
intent by default.  For variables of primitive, enum, and class
types, this has the effect of capturing the value of the
variable at task creation time.  Within the lexical scope of the
forall statement or expression, the variable name references the
captured value instead of the original value.

A formal can be given another intent explicitly by listing it
with that intent in the optional \sntx{task-intent-clause}.
For example, for variables of most types, the \chpl{ref} intent allows
the body of the forall loop to modify the corresponding original
variable or to read its updated value after concurrent modifications.
The \chpl{in} intent is an alternative way to obtain task-private
variables (\rsec{Task_Private_Variables}).
A \chpl{reduce} intent can be used to reduce values across iterations
of a forall or coforall loop.
Reduce intents are described in the \emph{Reduce Intents} technical note
in the online documentation:
\\ %formatting
\mbox{$$ $$ $$} %indent
\url{https://chapel-lang.org/docs/technotes/reduceIntents.html}

\begin{rationale}
A forall statement or expression may create tasks in its implementation.
Forall intents affect those tasks in the same way that task intents
\rsec{Task_Intents}
affect the behavior of a task construct such as a \chpl{coforall} loop.
\end{rationale}


\section{Task-Private Variables}
\label{Task_Private_Variables}
\index{task-private variables}
\index{shadow variables}
\index{data parallelism!task-private variables}
\index{data parallelism!shadow variables}
\index{statements!forall@\chpl{forall}!task-private variables}
\index{statements!forall@\chpl{forall}!shadow variables}

A \emph{task-private variable} declared in a forall loop results
in a separate shadow variable in each task created by the forall
loop's parallel iterator, as well as a "top-level" shadow variable
created at the top level of the parallel iterator itself.
In contrast to regular forall intents \rsec{Forall_Intents},
these shadow variables are unrelated to outer variables
of the same name, if any.

A given shadow variable is created at the start and destroyed
at the end of its task.
Within the lexical scope of the body of the forall statement or expression,
the variable name refers to the shadow variable created in the task
that executed the current yield statement.

The "top-level" shadow variable is created at the start and destroyed
at the end of the parallel iterator. It is referenced in those iterations
of the forall loop that are due to "top-level" yields, i.e. yields
that are outside any of the task constructs that the iterator may have.

The syntax of a task-private variable declaration in a forall statement's
with-clause is:

\begin{syntax}
task-private-var-decl:
  task-private-var-kind identifier type-part[OPT] initialization-part[OPT]

task-private-var-kind:
  `const'
  `var'
  `ref'
\end{syntax}

The declaration of a \chpl{const} or \chpl{var} task-private variable must
have at least one of \sntx{type-part} and \sntx{initialization-part}.
A \chpl{ref} task-private variable must have \sntx{initialization-part}
and cannot have \sntx{type-part}. A \chpl{ref} shadow variable
is a reference to the \sntx{initialization-part} as calculated at
the start of the corresponding task or the iterator.
\chpl{ref} shadow variables are never destroyed.

\begin{craychapel}
Currently task-private variables are not available for task constructs.
A regular variable declared at the start of the begin/cobegin/coforall
block can be used instead.
\end{craychapel}

\begin{chapelexample}{task-private-variable.chpl}
In the following example, the \chpl{writeln()} statement will observe
the first shadow variable 4 times: twice each for the yields
{\tt "before coforall"} and {\tt "after coforall"}.
An additional shadow variable will be created and observed twice
for each of the three \chpl{coforall} tasks.
\begin{chapel}
var cnt: atomic int;                     // count our shadow variables
record R { var id = cnt.fetchAdd(1); }

iter myIter() { yield ""; }              // serial iterator, unused

iter myIter(param tag) where tag == iterKind.standalone {
  for 1..2 do
    yield "before coforall";             // shadow var 0 ("top-level")
  coforall 1..3 do
    for 1..2 do
      yield "inside coforall";           // shadow vars 1..3
  for 1..2 do
    yield "after coforall";              // shadow var 0, again
}

forall str in myIter()
  with (var tpv: R)                      // declare a task-private variable
do
  writeln("shadow var: ", tpv.id, "  yield: ", str);
\end{chapel}
\begin{chapelprediff}
\#!/usr/bin/env sh
testname=$1
outfile=$2
sort $outfile > $outfile.2
mv $outfile.2 $outfile
\end{chapelprediff}
\begin{chapeloutput}
shadow var: 0  yield: after coforall
shadow var: 0  yield: after coforall
shadow var: 0  yield: before coforall
shadow var: 0  yield: before coforall
shadow var: 1  yield: inside coforall
shadow var: 1  yield: inside coforall
shadow var: 2  yield: inside coforall
shadow var: 2  yield: inside coforall
shadow var: 3  yield: inside coforall
shadow var: 3  yield: inside coforall
\end{chapeloutput}
\end{chapelexample}


\section{Promotion}
\label{Promotion}
\index{promotion}
\index{data parallelism!promotion}

A function that expects one or more scalar arguments but is called
with one or more arrays, domains, ranges, or iterators is promoted if
the element types of the arrays, the index types of the domains and/or
ranges, or the yielded types of the iterators can be resolved to the
type of the argument.  The rules of when an overloaded function can be
promoted are discussed in~\rsec{Function_Resolution}.

Functions that can be promoted include procedures, operators, casts,
and methods. Also note that since class and record field access
is performed with getter methods~(\rsec{Getter_Methods}), field
access can also be promoted.

If the original function returns a value or a reference, the
corresponding promoted expression is an iterator yielding each
computed value or reference.

When a promoted expression is used to initialize a variable,
such as \chpl{var X = A.x;} in the above example,
the variable's type will be inferred to be an array.
The array's domain is defined by the expression that causes promotion:

\begin{center}
\begin{tabular}[c]{|l|l|}
\hline
input expression & resulting array's domain \\
\hline
array    &  that array's domain \\
domain   &  that domain \\
range    &  one-dimensional domain built from that range \\
iterator &  1-based one-dimensional domain \\
\hline
\end{tabular}
\end{center}

\begin{future}
We would like to allow the iterator author to specify the shape
of the iterator, i.e. the domain of the array that would capture
the result of the corresponding promoted expression, such as
\begin{chapel}
var myArray = myScalarFunction(myIterator());
\end{chapel}
This will be helpful, for example, when the iterator yields
one value per an array or domain element that it iterates over
internally.
\end{future}

\begin{chapelexample}{promotion.chpl}
Given the array
\begin{chapel}
var A: [1..5] int = [i in 1..5] i;
\end{chapel}
and the function
\begin{chapel}
proc square(x: int) return x**2;
\end{chapel}
then the call \chpl{square(A)} results in the promotion of
the \chpl{square} function over the values in the array \chpl{A}.  The
result is an iterator that returns the
values \chpl{1}, \chpl{4}, \chpl{9}, \chpl{16}, and \chpl{25}.
\begin{chapelnoprint}
for s in square(A) do writeln(s);
\end{chapelnoprint}
\begin{chapeloutput}
1
4
9
16
25
\end{chapeloutput}
\end{chapelexample}

\begin{chapelexample}{field-promotion.chpl}
Given an array of points, such as \chpl{A} defined below:
\begin{chapel}
record Point {
  var x: real;
  var y: real;
}
var A: [1..5] Point = [i in 1..5] new Point(x=i, y=i);
\end{chapel}
the following statement will create a new array consisting of
the \chpl{x} field value for each value in A:
\begin{chapel}
var X = A.x;
\end{chapel}
and the following call will set the \chpl{y} field values for each
element in A to 1.0:
\begin{chapel}
A.y = 1.0;
\end{chapel}

\begin{chapelnoprint}
writeln(X);
writeln(A);
\end{chapelnoprint}
\begin{chapeloutput}
1.0 2.0 3.0 4.0 5.0
(x = 1.0, y = 1.0) (x = 2.0, y = 1.0) (x = 3.0, y = 1.0) (x = 4.0, y = 1.0) (x = 5.0, y = 1.0)
\end{chapeloutput}
\end{chapelexample}


\subsection{Default Arguments}
\label{Promotion_Default_Arguments}
\index{promotion!default arguments}

When a call is promoted and that call relied upon default
arguments~(\rsec{Default_Values}), the default argument expression can
be evaluated many times. For example:

\begin{chapelexample}{promotes-default.chpl}
\begin{chapel}
  var counter: atomic int;

  proc nextCounterValue():int {
    var i = counter.fetchAdd(1);
    return i;
  }

  proc assignCounter(ref x:int, counter=nextCounterValue()) {
    x = counter;
  }
\end{chapel}

Here the function assignCounter has a default argument
providing the next value from an atomic counter as the value to set.

\begin{chapel}
  var A: [1..5] int;
  assignCounter(A);
\end{chapel}

The assignCounter call uses both the default argument for counter as well
as promotion. When these features are combined, the default argument
will be evaluated once per promoted element. As a result, after this
command, A will contain the elements 0 1 2 3 4 in some order.

\begin{chapelnoprint}
writeln(A.sorted());
\end{chapelnoprint}
\begin{chapeloutput}
0 1 2 3 4
\end{chapeloutput}
\end{chapelexample}


\subsection{Zipper Promotion}
\label{Zipper_Promotion}
\index{promotion!zipper iteration}

Promotion also supports zippered iteration semantics as described
in~\rsec{Zipper_Iteration} and~\rsec{Parallel_Iterators} for parallel
iteration.

Consider a function \chpl{f} with formal
arguments \chpl{s1}, \chpl{s2},~... that are promoted and formal
arguments \chpl{a1}, \chpl{a2},~... that are not promoted.  The call
\begin{chapel}
f(s1, s2, ..., a1, a2, ...)
\end{chapel}
is equivalent to
\begin{chapel}
[(e1, e2, ...) in zip(s1, s2, ...)] f(e1, e2, ..., a1, a2, ...)
\end{chapel}
The usual constraints of zipper iteration apply to zipper promotion so
the promoted actuals must have the same shape.

A zipper promotion can be captured in a variable, such as
\chpl{var X = f(s1, s2, ..., a1, a2, ...);} using the above example.
If so, the domain of the resulting array is defined by the first argument
that causes promotion. The rules are the same as in the non-zipper case.


\begin{chapelexample}{zipper-promotion.chpl}
Given a function defined as
\begin{chapel}
proc foo(i: int, j: int) {
  return (i,j);
}
\end{chapel}
and a call to this function written
\begin{chapel}
writeln(foo(1..3, 4..6));
\end{chapel}
then the output is
\begin{chapelprintoutput}{}
(1, 4) (2, 5) (3, 6)
\end{chapelprintoutput}
\end{chapelexample}


\subsection{Whole Array Operations and Evaluation Order}
\label{Whole_Array_Operations}
\index{whole array assignment}
\index{whole array operations}
\index{arrays!assignment}
\index{assignment!whole array}
\index{data parallelism!evaluation order}

Whole array operations are a form of promotion as applied to operators
rather than functions.

Whole array assignment is one example. It is is implicitly parallel.
The array assignment statement:
\begin{chapel}
LHS = RHS;
\end{chapel}
is equivalent to
\begin{chapel}
forall (e1,e2) in zip(LHS,RHS) do
  e1 = e2;
\end{chapel}

The semantics of whole array assignment and promotion are different
from most array programming languages.  Specifically, the compiler
does not insert array temporaries for such operations if any of the
right-hand side array expressions alias the left-hand side expression.

%
% sungeun 4/8/2011
% Did not convert this one due to non-deterministic output
%
\begin{example}
If \chpl{A} is an array declared over the indices \chpl{1..5}, then
the following codes are not equivalent:
\begin{chapel}
A[2..4] = A[1..3] + A[3..5];
\end{chapel}
and
\begin{chapel}
var T = A[1..3] + A[3..5];
A[2..4] = T;
\end{chapel}
This follows because, in the former code, some of the new values that
are assigned to \chpl{A} may be read to compute the sum depending on
the number of tasks used to implement the data parallel statement.
\end{example}



\section{Reductions and Scans}
\label{Reductions_and_Scans}
\index{reductions}
\index{scans}
\index{data parallelism!reductions}
\index{data parallelism!scans}

Chapel provides reduction and scan expressions that apply operators to
aggregate expressions in stylized ways.  Reduction expressions
collapse the aggregate's values down to a summary value.  Scan
expressions compute an aggregate of results where each result value
stores the result of a reduction applied to all of the elements in the
aggregate up to that expression.  Chapel provides a number of predefined
reduction and scan operators, and also supports a mechanism for the
user to define additional reductions and
scans (Chapter~\ref{User_Defined_Reductions_and_Scans}).

\subsection{Reduction Expressions}
\label{reduce}
\index{reduction expressions}
\index{expressions!reduction}

A reduction expression applies a reduction operator to an aggregate
expression, collapsing the aggregate's dimensions down into a result
value (typically a scalar or summary expression that is independent of
the input aggregate's size).  For example, a sum reduction computes
the sum of all the elements in the input aggregate expression.

The syntax for a reduction expression is given by:
\begin{syntax}
reduce-expression:
  reduce-scan-operator `reduce' iteratable-expression
  class-type `reduce' iteratable-expression

reduce-scan-operator: one of
  + $ $ $ $ * $ $ $ $ && $ $ $ $ || $ $ $ $ & $ $ $ $ | $ $ $ $ ^ $ $ $ $ `min' $ $ $ $ `max' $ $ $ $ `minloc' $ $ $ $ `maxloc'
\end{syntax}

Chapel's predefined reduction operators are defined
by \sntx{reduce-scan-operator} above.  In order, they are: sum,
product, logical-and, logical-or, bitwise-and, bitwise-or,
bitwise-exclusive-or, minimum, maximum, minimum-with-location, and
maximum-with-location.  The minimum reduction returns the minimum
value as defined by the \verb@<@ operator.  The maximum reduction
returns the maximum value as defined by the \verb@>@ operator.  The
minimum-with-location reduction returns the lowest index position with
the minimum value (as defined by the \verb@<@ operator).  The
maximum-with-location reduction returns the lowest index position with
the maximum value (as defined by the \verb@>@ operator).

The expression on the right-hand side of the \chpl{reduce} keyword
can be of any type that can be iterated over, provided
the reduction operator can be applied to the values yielded
by the iteration. For example, the bitwise-and
operator can be applied to arrays of boolean or integral types to
compute the bitwise-and of all the values in the array.

For the minimum-with-location and maximum-with-location reductions,
the argument on the right-hand side of the \chpl{reduce} keyword
must be a 2-tuple. Its first component is the collection
of values for which the minimum/maximum value is to be computed.  The
second argument component is a collection of indices with the same size and
shape that provides names for the locations of the values in the first
component.  The reduction returns a tuple containing the
minimum/maximum value in the first argument component and the value
at the corresponding location in the second argument component.

\begin{chapelexample}{reduce-loc.chpl}
The first line below computes the smallest element in an array
\chpl{A} as well as its index, storing the results in \chpl{minA} and
\chpl{minALoc}, respectively.  It then computes the largest element in
a forall expression making calls to a function \chpl{foo()}, storing
the value and its number in \chpl{maxVal} and \chpl{maxValNum}.
\begin{chapelnoprint}
config const n = 10;
const D = {1..n};
var A: [D] int = [i in D] i % 7;
proc foo(x) return x % 7;
\end{chapelnoprint}
\begin{chapel}
var (minA, minALoc) = minloc reduce zip(A, A.domain); 
var (maxVal, maxValNum) = maxloc reduce zip([i in 1..n] foo(i), 1..n);
\end{chapel}
\begin{chapelnoprint}
writeln((minA, minALoc));
writeln((maxVal, maxValNum));
\end{chapelnoprint}
\begin{chapeloutput}
(0, 7)
(6, 6)
\end{chapeloutput}
\end{chapelexample}

User-defined reductions are specified by preceding the
keyword \chpl{reduce} by the class type that implements the reduction
interface as described in~\rsec{User_Defined_Reductions_and_Scans}.

\subsection{Scan Expressions}
\label{scan}
\index{scan expressions}
\index{expressions!scan}

A scan expression applies a scan operator to an aggregate expression,
resulting in an aggregate expression of the same size and shape.  The
output values represent the result of the operator applied to all
elements up to and including the corresponding element in the input.

The syntax for a scan expression is given by:
\begin{syntax}
scan-expression:
  reduce-scan-operator `scan' iteratable-expression
  class-type `scan' iteratable-expression
\end{syntax}

The predefined scans are defined by \sntx{reduce-scan-operator}.  These
are identical to the predefined reductions and are described
in~\rsec{reduce}.

The expression on the right-hand side of the scan can be of any type
that can be iterated over and to which the operator can be applied.

%
% sungeun: 4/8/2011
% Did not convert this one yet due to warning about serializing scans
%
\begin{example}
Given an array
\begin{chapel}
var A: [1..3] int = 1;
\end{chapel}
that is initialized such that each element contains one, then the code
\begin{chapel}
writeln(+ scan A);
\end{chapel}
outputs the results of scanning the array with the sum operator.  The
output is
\begin{chapelprintoutput}{}
1 2 3
\end{chapelprintoutput}
\end{example}

User-defined scans are specified by preceding the keyword \chpl{scan}
by the class type that implements the scan interface as described
in Chapter~\ref{User_Defined_Reductions_and_Scans}.

\section{Configuration Constants for Default Data Parallelism}
\label{data_parallel_knobs}
\index{data parallelism!knobs for default data parallelism}
\index{data parallelism!configuration constants}
\index{dataParTasksPerLocale@\chpl{dataParTasksPerLocale}}
\index{dataParIgnoreRunningTasks@\chpl{dataParIgnoreRunningTasks}}
\index{dataParMinGranularity@\chpl{dataParMinGranularity}}

The following configuration constants are provided to control the
degree of data parallelism over ranges, default domains, and default
arrays:

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
{\bf Config Const} & {\bf Type} & {\bf Default} \\
\hline
\chpl{dataParTasksPerLocale} & \chpl{int} &
top level \chpl{.maxTaskPar}~(see~\rsec{Locale_Methods}) \\
\chpl{dataParIgnoreRunningTasks} & \chpl{bool} & \chpl{true} \\
\chpl{dataParMinGranularity} & \chpl{int} & \chpl{1} \\
\hline
\end{tabular}
\end{center}

The configuration constant \chpl{dataParTasksPerLocale} specifies the
number of tasks to use when executing a forall loop over a range,
default domain, or default array.  The actual number of tasks may be
fewer depending on the other two configuration constants.  A value of
zero results in using the default value.

The configuration constant \chpl{dataParIgnoreRunningTasks}, when
true, has no effect on the number of tasks to use to execute the
forall loop.  When false, the number of tasks per locale is decreased
by the number of tasks that are already running on the locale, with a
minimum value of one.

The configuration constant \chpl{dataParMinGranularity} specifies the
minimum number of iterations per task created.  The number of tasks is
decreased so that the number of iterations per task is never less than
the specified value.

For distributed domains and arrays that have these same configuration
constants (\eg, Block and Cyclic distributions), these same
module level configuration constants are used to specify their
default behavior within each locale.
