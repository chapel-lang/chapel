.\" Automatically generated by Pandoc 2.9.2.1
.\"
.TH "fi_efa" "7" "2024\-01\-23" "Libfabric Programmer\[cq]s Manual" "Libfabric v1.21.0"
.hy
.SH NAME
.PP
fi_efa - The Amazon Elastic Fabric Adapter (EFA) Provider
.SH OVERVIEW
.PP
The EFA provider supports the Elastic Fabric Adapter (EFA) device on
Amazon EC2.
EFA provides reliable and unreliable datagram send/receive with direct
hardware access from userspace (OS bypass).
.SH SUPPORTED FEATURES
.PP
The following features are supported:
.TP
\f[I]Endpoint types\f[R]
The provider supports endpoint type \f[I]FI_EP_DGRAM\f[R], and
\f[I]FI_EP_RDM\f[R] on a new Scalable (unordered) Reliable Datagram
protocol (SRD).
SRD provides support for reliable datagrams and more complete error
handling than typically seen with other Reliable Datagram (RD)
implementations.
The EFA provider provides segmentation, reassembly of out-of-order
packets to provide send-after-send ordering guarantees to applications
via its \f[I]FI_EP_RDM\f[R] endpoint.
.TP
\f[I]RDM Endpoint capabilities\f[R]
The following data transfer interfaces are supported via the
\f[I]FI_EP_RDM\f[R] endpoint: \f[I]FI_MSG\f[R], \f[I]FI_TAGGED\f[R], and
\f[I]FI_RMA\f[R].
\f[I]FI_SEND\f[R], \f[I]FI_RECV\f[R], \f[I]FI_DIRECTED_RECV\f[R],
\f[I]FI_MULTI_RECV\f[R], and \f[I]FI_SOURCE\f[R] capabilities are
supported.
The endpoint provides send-after-send guarantees for data operations.
The \f[I]FI_EP_RDM\f[R] endpoint does not have a maximum message size.
.TP
\f[I]DGRAM Endpoint capabilities\f[R]
The DGRAM endpoint only supports \f[I]FI_MSG\f[R] capability with a
maximum message size of the MTU of the underlying hardware
(approximately 8 KiB).
.TP
\f[I]Address vectors\f[R]
The provider supports \f[I]FI_AV_TABLE\f[R] and \f[I]FI_AV_MAP\f[R]
address vector types.
\f[I]FI_EVENT\f[R] is unsupported.
.TP
\f[I]Completion events\f[R]
The provider supports \f[I]FI_CQ_FORMAT_CONTEXT\f[R],
\f[I]FI_CQ_FORMAT_MSG\f[R], and \f[I]FI_CQ_FORMAT_DATA\f[R].
\f[I]FI_CQ_FORMAT_TAGGED\f[R] is supported on the RDM endpoint.
Wait objects are not currently supported.
.TP
\f[I]Modes\f[R]
The provider requires the use of \f[I]FI_MSG_PREFIX\f[R] when running
over the DGRAM endpoint, and requires \f[I]FI_MR_LOCAL\f[R] for all
memory registrations on the DGRAM endpoint.
.TP
\f[I]Memory registration modes\f[R]
The RDM endpoint does not require memory registration for send and
receive operations, i.e.\ it does not require \f[I]FI_MR_LOCAL\f[R].
Applications may specify \f[I]FI_MR_LOCAL\f[R] in the MR mode flags in
order to use descriptors provided by the application.
The \f[I]FI_EP_DGRAM\f[R] endpoint only supports \f[I]FI_MR_LOCAL\f[R].
.TP
\f[I]Progress\f[R]
RDM and DGRAM endpoints support \f[I]FI_PROGRESS_MANUAL\f[R].
EFA erroneously claims the support for \f[I]FI_PROGRESS_AUTO\f[R],
despite not properly supporting automatic progress.
Unfortunately, some Libfabric consumers also ask for
\f[I]FI_PROGRESS_AUTO\f[R] when they only require
\f[I]FI_PROGRESS_MANUAL\f[R], and fixing this bug would break those
applications.
This will be fixed in a future version of the EFA provider by adding
proper support for \f[I]FI_PROGRESS_AUTO\f[R].
.TP
\f[I]Threading\f[R]
The RDM endpoint supports \f[I]FI_THREAD_SAFE\f[R], the DGRAM endpoint
supports \f[I]FI_THREAD_DOMAIN\f[R], i.e.\ the provider is not thread
safe when using the DGRAM endpoint.
.SH LIMITATIONS
.PP
The DGRAM endpoint does not support \f[I]FI_ATOMIC\f[R] interfaces.
For RMA operations, completion events for RMA targets
(\f[I]FI_RMA_EVENT\f[R]) is not supported.
The DGRAM endpoint does not fully protect against resource overruns, so
resource management is disabled for this endpoint
(\f[I]FI_RM_DISABLED\f[R]).
.PP
No support for selective completions.
.PP
No support for counters for the DGRAM endpoint.
.PP
No support for inject.
.PP
When using FI_HMEM for AWS Neuron or Habana SynapseAI buffers, the
provider requires peer to peer transaction support between the EFA and
the FI_HMEM device.
Therefore, the FI_HMEM_P2P_DISABLED option is not supported by the EFA
provider for AWS Neuron or Habana SynapseAI.
.SH PROVIDER SPECIFIC ENDPOINT LEVEL OPTION
.TP
\f[I]FI_OPT_EFA_RNR_RETRY\f[R]
Defines the number of RNR retry.
The application can use it to reset RNR retry counter via the call to
fi_setopt.
Note that this option must be set before the endpoint is enabled.
Otherwise, the call will fail.
Also note that this option only applies to RDM endpoint.
.TP
\f[I]FI_OPT_EFA_EMULATED_READ, FI_OPT_EFA_EMULATED_WRITE, FI_OPT_EFA_EMULATED_ATOMICS - bool\f[R]
These options only apply to the fi_getopt() call.
They are used to query the EFA provider to determine if the endpoint is
emulating Read, Write, and Atomic operations (return value is true), or
if these operations are assisted by hardware support (return value is
false).
.TP
\f[I]FI_OPT_EFA_USE_DEVICE_RDMA - bool\f[R]
Only available if the application selects a libfabric API version >=
1.18.
This option allows an application to change libfabric\[cq]s behavior
with respect to RDMA transfers.
Note that there is also an environment variable FI_EFA_USE_DEVICE_RDMA
which the user may set as well.
If the environment variable and the argument provided with this variable
are in conflict, then fi_setopt will return -FI_EINVAL, and the
environment variable will be respected.
If the hardware does not support RDMA and the argument is true, then
fi_setopt will return -FI_EOPNOTSUPP.
If the application uses API version < 1.18, the argument is ignored and
fi_setopt returns -FI_ENOPROTOOPT.
The default behavior for RDMA transfers depends on API version.
For API >= 1.18 RDMA is enabled by default on any hardware which
supports it.
For API<1.18, RDMA is enabled by default only on certain newer hardware
revisions.
.TP
\f[I]FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES - bool\f[R]
It is used to force the endpoint to use in-order send/recv operation for
each 128 bytes aligned block.
Enabling the option will guarantee data inside each 128 bytes aligned
block being sent and received in order, it will also guarantee data to
be delivered to the receive buffer only once.
If endpoint is not able to support this feature, it will return
-FI_EOPNOTSUPP for the call to fi_setopt().
.TP
\f[I]FI_OPT_EFA_WRITE_IN_ORDER_ALIGNED_128_BYTES - bool\f[R]
It is used to set the endpoint to use in-order RDMA write operation for
each 128 bytes aligned block.
Enabling the option will guarantee data inside each 128 bytes aligned
block being written in order, it will also guarantee data to be
delivered to the target buffer only once.
If endpoint is not able to support this feature, it will return
-FI_EOPNOTSUPP for the call to fi_setopt().
.SH PROVIDER SPECIFIC DOMAIN OPS
.PP
The efa provider exports extensions for operations that are not provided
by the standard libfabric interface.
These extensions are available via the \[lq]\f[C]fi_ext_efa.h\f[R]\[rq]
header file.
.SS Domain Operation Extension
.PP
Domain operation extension is obtained by calling \f[C]fi_open_ops\f[R]
(see \f[C]fi_domain(3)\f[R])
.IP
.nf
\f[C]
int fi_open_ops(struct fid *domain, const char *name, uint64_t flags,
    void **ops, void *context);
\f[R]
.fi
.PP
and requesting \f[C]FI_EFA_DOMAIN_OPS\f[R] in \f[C]name\f[R].
\f[C]fi_open_ops\f[R] returns \f[C]ops\f[R] as the pointer to the
function table \f[C]fi_efa_ops_domain\f[R] defined as follows:
.IP
.nf
\f[C]
struct fi_efa_ops_domain {
    int (*query_mr)(struct fid_mr *mr, struct fi_efa_mr_attr *mr_attr);
};
\f[R]
.fi
.PP
It contains the following operations
.SS query_mr
.PP
This op query an existing memory registration as input, and outputs the
efa specific mr attribute which is defined as follows
.IP
.nf
\f[C]
struct fi_efa_mr_attr {
    uint16_t ic_id_validity;
    uint16_t recv_ic_id;
    uint16_t rdma_read_ic_id;
    uint16_t rdma_recv_ic_id;
};
\f[R]
.fi
.TP
\f[I]ic_id_validity\f[R]
Validity mask of interconnect id fields.
Currently the following bits are supported in the mask:
.RS
.PP
FI_EFA_MR_ATTR_RECV_IC_ID: recv_ic_id has a valid value.
.PP
FI_EFA_MR_ATTR_RDMA_READ_IC_ID: rdma_read_ic_id has a valid value.
.PP
FI_EFA_MR_ATTR_RDMA_RECV_IC_ID: rdma_recv_ic_id has a valid value.
.RE
.TP
\f[I]recv_ic_id\f[R]
Physical interconnect used by the device to reach the MR for receive
operation.
It is only valid when \f[C]ic_id_validity\f[R] has the
\f[C]FI_EFA_MR_ATTR_RECV_IC_ID\f[R] bit.
.TP
\f[I]rdma_read_ic_id\f[R]
Physical interconnect used by the device to reach the MR for RDMA read
operation.
It is only valid when \f[C]ic_id_validity\f[R] has the
\f[C]FI_EFA_MR_ATTR_RDMA_READ_IC_ID\f[R] bit.
.TP
\f[I]rdma_recv_ic_id\f[R]
Physical interconnect used by the device to reach the MR for RDMA write
receive.
It is only valid when \f[C]ic_id_validity\f[R] has the
\f[C]FI_EFA_MR_ATTR_RDMA_RECV_IC_ID\f[R] bit.
.SS Return value
.PP
\f[B]query_mr()\f[R] returns 0 on success, or the value of errno on
failure (which indicates the failure reason).
.SH RUNTIME PARAMETERS
.TP
\f[I]FI_EFA_TX_SIZE\f[R]
Maximum number of transmit operations before the provider returns
-FI_EAGAIN.
For only the RDM endpoint, this parameter will cause transmit operations
to be queued when this value is set higher than the default and the
transmit queue is full.
.TP
\f[I]FI_EFA_RX_SIZE\f[R]
Maximum number of receive operations before the provider returns
-FI_EAGAIN.
.SH RUNTIME PARAMETERS SPECIFIC TO RDM ENDPOINT
.PP
These OFI runtime parameters apply only to the RDM endpoint.
.TP
\f[I]FI_EFA_RX_WINDOW_SIZE\f[R]
Maximum number of MTU-sized messages that can be in flight from any
single endpoint as part of long message data transfer.
.TP
\f[I]FI_EFA_TX_QUEUE_SIZE\f[R]
Depth of transmit queue opened with the NIC.
This may not be set to a value greater than what the NIC supports.
.TP
\f[I]FI_EFA_RECVWIN_SIZE\f[R]
Size of out of order reorder buffer (in messages).
Messages received out of this window will result in an error.
.TP
\f[I]FI_EFA_CQ_SIZE\f[R]
Size of any cq created, in number of entries.
.TP
\f[I]FI_EFA_MR_CACHE_ENABLE\f[R]
Enables using the mr cache and in-line registration instead of a bounce
buffer for iov\[cq]s larger than max_memcpy_size.
Defaults to true.
When disabled, only uses a bounce buffer
.TP
\f[I]FI_EFA_MR_MAX_CACHED_COUNT\f[R]
Sets the maximum number of memory registrations that can be cached at
any time.
.TP
\f[I]FI_EFA_MR_MAX_CACHED_SIZE\f[R]
Sets the maximum amount of memory that cached memory registrations can
hold onto at any time.
.TP
\f[I]FI_EFA_MAX_MEMCPY_SIZE\f[R]
Threshold size switch between using memory copy into a pre-registered
bounce buffer and memory registration on the user buffer.
.TP
\f[I]FI_EFA_MTU_SIZE\f[R]
Overrides the default MTU size of the device.
.TP
\f[I]FI_EFA_RX_COPY_UNEXP\f[R]
Enables the use of a separate pool of bounce-buffers to copy unexpected
messages out of the pre-posted receive buffers.
.TP
\f[I]FI_EFA_RX_COPY_OOO\f[R]
Enables the use of a separate pool of bounce-buffers to copy
out-of-order RTS packets out of the pre-posted receive buffers.
.TP
\f[I]FI_EFA_MAX_TIMEOUT\f[R]
Maximum timeout (us) for backoff to a peer after a receiver not ready
error.
.TP
\f[I]FI_EFA_TIMEOUT_INTERVAL\f[R]
Time interval (us) for the base timeout to use for exponential backoff
to a peer after a receiver not ready error.
.TP
\f[I]FI_EFA_ENABLE_SHM_TRANSFER\f[R]
Enable SHM provider to provide the communication across all intra-node
processes.
SHM transfer will be disabled in the case where
\f[C]ptrace protection\f[R] is turned on.
You can turn it off to enable shm transfer.
.PP
FI_EFA_ENABLE_SHM_TRANSFER is parsed during the fi_domain call and is
related to the FI_OPT_SHARED_MEMORY_PERMITTED endpoint option.
If FI_EFA_ENABLE_SHM_TRANSFER is set to true, the
FI_OPT_SHARED_MEMORY_PERMITTED endpoint option overrides
FI_EFA_ENABLE_SHM_TRANSFER.
If FI_EFA_ENABLE_SHM_TRANSFER is set to false, but the
FI_OPT_SHARED_MEMORY_PERMITTED is set to true, the
FI_OPT_SHARED_MEMORY_PERMITTED setopt call will fail with -FI_EINVAL.
.TP
\f[I]FI_EFA_SHM_AV_SIZE\f[R]
Defines the maximum number of entries in SHM provider\[cq]s address
vector.
.TP
\f[I]FI_EFA_SHM_MAX_MEDIUM_SIZE\f[R]
Defines the switch point between small/medium message and large message.
The message larger than this switch point will be transferred with large
message protocol.
NOTE: This parameter is now deprecated.
.TP
\f[I]FI_EFA_INTER_MAX_MEDIUM_MESSAGE_SIZE\f[R]
The maximum size for inter EFA messages to be sent by using medium
message protocol.
Messages which can fit in one packet will be sent as eager message.
Messages whose sizes are smaller than this value will be sent using
medium message protocol.
Other messages will be sent using CTS based long message protocol.
.TP
\f[I]FI_EFA_FORK_SAFE\f[R]
Enable fork() support.
This may have a small performance impact and should only be set when
required.
Applications that require to register regions backed by huge pages and
also require fork support are not supported.
.TP
\f[I]FI_EFA_RUNT_SIZE\f[R]
The maximum number of bytes that will be eagerly sent by inflight
messages uses runting read message protocol (Default 307200).
.TP
\f[I]FI_EFA_INTER_MIN_READ_MESSAGE_SIZE\f[R]
The minimum message size in bytes for inter EFA read message protocol.
If instance support RDMA read, messages whose size is larger than this
value will be sent by read message protocol.
(Default 1048576).
.TP
\f[I]FI_EFA_INTER_MIN_READ_WRITE_SIZE\f[R]
The mimimum message size for emulated inter EFA write to use read write
protocol.
If firmware support RDMA read, and FI_EFA_USE_DEVICE_RDMA is 1, write
requests whose size is larger than this value will use the read write
protocol (Default 65536).
If the firmware supports RDMA write, device RDMA write will always be
used.
.TP
\f[I]FI_EFA_USE_DEVICE_RDMA\f[R]
Specify whether to require or ignore RDMA features of the EFA device.
- When set to 1/true/yes/on, all RDMA features of the EFA device are
used.
But if EFA device does not support RDMA and FI_EFA_USE_DEVICE_RDMA is
set to 1/true/yes/on, user\[cq]s application is aborted and a warning
message is printed.
- When set to 0/false/no/off, libfabric will emulate all fi_rma
operations instead of offloading them to the EFA network device.
Libfabric will not use device RDMA to implement send/receive operations.
- If not set, RDMA operations will occur when available based on RDMA
device ID/version.
.TP
\f[I]FI_EFA_USE_HUGE_PAGE\f[R]
Specify Whether EFA provider can use huge page memory for internal
buffer.
Using huge page memory has a small performance advantage, but can cause
system to run out of huge page memory.
By default, EFA provider will use huge page unless FI_EFA_FORK_SAFE is
set to 1/on/true.
.SH SEE ALSO
.PP
\f[C]fabric\f[R](7), \f[C]fi_provider\f[R](7), \f[C]fi_getinfo\f[R](3)
.SH AUTHORS
OpenFabrics.
